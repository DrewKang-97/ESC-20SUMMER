{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEEK1_HW_Minju_Jo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Threshold가 낮으면 가입이 쉽다. -> 원하지 않는 사람인데 가입할 확률이 높아진다.\n",
    "- 실제 False인 것을 True라고 예측한다.\n",
    "- FP 높아짐\n",
    "- Type 2 error 높아짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2-1\n",
    "- Accuracy = (TP + TN) / (TP + FN + FP + TN)\n",
    "- Precision = TP / (TP + FP) # 모델이 True라고 분류한 것 중, 실제 True의 비율\n",
    "- Recall = TP / (TP + FN) # 실제 True인 것 중, 모델이 True라고 예측한 비율"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2-2\n",
    "\n",
    "- Precision and recall 예시 - 1박2일 콜라와 까나리액젓 복불복\n",
    "- Precision = 1박 2일 멤버가 콜라라고 생각한 컵 중 진짜 콜라가 담긴 컵의 비율\n",
    "- Recall = 콜라가 담긴 컵 중 멤버가 선택한 컵의 비율\n",
    "- 성공확률의 threshold를 높힌다 = 실제 콜라가 든 컵을 고르는 것이 어려워진다\n",
    "- threshold를 높히는 것이 좋다\n",
    "- 1) 시청자 입장 : 더 재밌다\n",
    "- 2) 멤버 : 웃기는 것이 목적이므로 까나리액젓 먹을수록 좋다\n",
    "- 3) 제작진 : 웃기면 시청률 더 잘 나오니까 콜라 든 컵 고르기 어려울수록 좋다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3\n",
    "### Identifying Handwritten digits using Logistic Regression in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets #MNIST dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "input_size = 784\n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST Dataset (Images and Labels) \n",
    "train_dataset = dsets.MNIST(root ='./data', train = True, \n",
    "                            transform = transforms.ToTensor(), \n",
    "                            download = True) \n",
    "\n",
    "test_dataset = dsets.MNIST(root ='./data', \n",
    "                           train = False, \n",
    "                           transform = transforms.ToTensor()) \n",
    "\n",
    "# Dataset Loader (Input Pipline) \n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, \n",
    "                                           batch_size = batch_size, \n",
    "                                           shuffle = True) \n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset, \n",
    "                                          batch_size = batch_size, \n",
    "                                          shuffle = False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(input_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and the optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our Tasks\n",
    "\n",
    "- 1.Reset all gradients to 0.\n",
    "- 2.Make a forward pass.\n",
    "- 3.Calculate the loss.\n",
    "- 4.Perform backpropagation.\n",
    "- 5.Update all weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [ 1/ 5], Step : [ 100/ 600], Loss: 2.1877\n",
      "Epoch : [ 1/ 5], Step : [ 200/ 600], Loss: 2.1163\n",
      "Epoch : [ 1/ 5], Step : [ 300/ 600], Loss: 1.9712\n",
      "Epoch : [ 1/ 5], Step : [ 400/ 600], Loss: 1.9093\n",
      "Epoch : [ 1/ 5], Step : [ 500/ 600], Loss: 1.9324\n",
      "Epoch : [ 1/ 5], Step : [ 600/ 600], Loss: 1.7809\n",
      "Epoch : [ 2/ 5], Step : [ 100/ 600], Loss: 1.7433\n",
      "Epoch : [ 2/ 5], Step : [ 200/ 600], Loss: 1.5639\n",
      "Epoch : [ 2/ 5], Step : [ 300/ 600], Loss: 1.5642\n",
      "Epoch : [ 2/ 5], Step : [ 400/ 600], Loss: 1.5788\n",
      "Epoch : [ 2/ 5], Step : [ 500/ 600], Loss: 1.4927\n",
      "Epoch : [ 2/ 5], Step : [ 600/ 600], Loss: 1.5857\n",
      "Epoch : [ 3/ 5], Step : [ 100/ 600], Loss: 1.4263\n",
      "Epoch : [ 3/ 5], Step : [ 200/ 600], Loss: 1.3033\n",
      "Epoch : [ 3/ 5], Step : [ 300/ 600], Loss: 1.3512\n",
      "Epoch : [ 3/ 5], Step : [ 400/ 600], Loss: 1.2370\n",
      "Epoch : [ 3/ 5], Step : [ 500/ 600], Loss: 1.1972\n",
      "Epoch : [ 3/ 5], Step : [ 600/ 600], Loss: 1.2977\n",
      "Epoch : [ 4/ 5], Step : [ 100/ 600], Loss: 1.2417\n",
      "Epoch : [ 4/ 5], Step : [ 200/ 600], Loss: 1.2143\n",
      "Epoch : [ 4/ 5], Step : [ 300/ 600], Loss: 1.1873\n",
      "Epoch : [ 4/ 5], Step : [ 400/ 600], Loss: 1.0456\n",
      "Epoch : [ 4/ 5], Step : [ 500/ 600], Loss: 1.0312\n",
      "Epoch : [ 4/ 5], Step : [ 600/ 600], Loss: 1.1561\n",
      "Epoch : [ 5/ 5], Step : [ 100/ 600], Loss: 1.1450\n",
      "Epoch : [ 5/ 5], Step : [ 200/ 600], Loss: 1.0694\n",
      "Epoch : [ 5/ 5], Step : [ 300/ 600], Loss: 1.1137\n",
      "Epoch : [ 5/ 5], Step : [ 400/ 600], Loss: 1.1147\n",
      "Epoch : [ 5/ 5], Step : [ 500/ 600], Loss: 1.0299\n",
      "Epoch : [ 5/ 5], Step : [ 600/ 600], Loss: 1.0056\n"
     ]
    }
   ],
   "source": [
    "# Training the Model\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images.view(-1, 28*28))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if(i+1) % 100 == 0:\n",
    "            print(\"Epoch : [% d/% d], Step : [% d/% d], Loss: %.4f\"\n",
    "                 % (epoch + 1, num_epochs, i+1, len(train_dataset) // batch_size, loss.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 10000 test images : 82 %\n"
     ]
    }
   ],
   "source": [
    "# Test the Model\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for images, labels in test_loader:\n",
    "    images = Variable(images.view(-1, 28*28))\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "    \n",
    "print(\"Accuracy of the model on the 10000 test images : %d %%\" %(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mySGD(train_data, lr, n_iter, k, divideby):\n",
    "    \n",
    "    # Initially we will keep our W and B as 0 as per the Training Data\n",
    "    w=np.zeros(shape=(1,train_data.shape[1]-1))\n",
    "    b=0\n",
    "    \n",
    "    cur_iter=1\n",
    "    while(cur_iter<=n_iter): \n",
    "\n",
    "        # We will create a small training data set of size K\n",
    "        temp=train_data.sample(k)\n",
    "        \n",
    "        # We create our X and Y from the above temp dataset\n",
    "        x=train_X\n",
    "        y=train_y\n",
    "        \n",
    "        # We keep our initial gradients as 0\n",
    "        w_gradient=np.zeros(shape=(1,train_data.shape[1]-1))\n",
    "        b_gradient=0\n",
    "        \n",
    "        for i in range(k): # Calculating gradients for point in our K sized dataset\n",
    "            prediction=np.dot(w,x[i])+b\n",
    "            w_gradient=w_gradient+(-2)*x[i]*(y[i]-(prediction))\n",
    "            b_gradient=b_gradient+(-2)*(y[i]-(prediction))\n",
    "        \n",
    "        #Updating the weights(W) and Bias(b) with the above calculated Gradients\n",
    "        w=w-learning_rate*(w_gradient/k)\n",
    "        b=b-learning_rate*(b_gradient/k)\n",
    "        \n",
    "        # Incrementing the iteration value\n",
    "        cur_iter=cur_iter+1\n",
    "        \n",
    "        #Dividing the learning rate by the specified value\n",
    "        learning_rate=learning_rate/divideby\n",
    "        \n",
    "    return w,b #Returning the weights and Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer_test(new_optim):\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = Variable(images.view(-1, 28*28))\n",
    "            labels = Variable(labels)\n",
    "\n",
    "            # Forward + Backward + Optimize\n",
    "            new_optim.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            new_optim.step()\n",
    "\n",
    "            if(i+1) % 100 == 0:\n",
    "                print(\"Epoch : [% d/% d], Step : [% d/% d], Loss: %.4f\"\n",
    "                     % (epoch + 1, num_epochs, i+1, len(train_dataset) // batch_size, loss.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_adam = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "optim_rmsprop = torch.optim.RMSprop(model.parameters(), lr = learning_rate)\n",
    "optim_sgd_mom = torch.optim.SGD(model.parameters(), lr = learning_rate, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in test_loader:\n",
    "        images = Variable(images.view(-1, 28*28))\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "\n",
    "    print(\"Accuracy of the model on the 10000 test images : %d %%\" %(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [ 1/ 5], Step : [ 100/ 600], Loss: 0.4995\n",
      "Epoch : [ 1/ 5], Step : [ 200/ 600], Loss: 0.4414\n",
      "Epoch : [ 1/ 5], Step : [ 300/ 600], Loss: 0.4156\n",
      "Epoch : [ 1/ 5], Step : [ 400/ 600], Loss: 0.3486\n",
      "Epoch : [ 1/ 5], Step : [ 500/ 600], Loss: 0.2761\n",
      "Epoch : [ 1/ 5], Step : [ 600/ 600], Loss: 0.3601\n",
      "Epoch : [ 2/ 5], Step : [ 100/ 600], Loss: 0.2773\n",
      "Epoch : [ 2/ 5], Step : [ 200/ 600], Loss: 0.3580\n",
      "Epoch : [ 2/ 5], Step : [ 300/ 600], Loss: 0.3625\n",
      "Epoch : [ 2/ 5], Step : [ 400/ 600], Loss: 0.3708\n",
      "Epoch : [ 2/ 5], Step : [ 500/ 600], Loss: 0.3342\n",
      "Epoch : [ 2/ 5], Step : [ 600/ 600], Loss: 0.3030\n",
      "Epoch : [ 3/ 5], Step : [ 100/ 600], Loss: 0.3964\n",
      "Epoch : [ 3/ 5], Step : [ 200/ 600], Loss: 0.3015\n",
      "Epoch : [ 3/ 5], Step : [ 300/ 600], Loss: 0.3147\n",
      "Epoch : [ 3/ 5], Step : [ 400/ 600], Loss: 0.2501\n",
      "Epoch : [ 3/ 5], Step : [ 500/ 600], Loss: 0.2267\n",
      "Epoch : [ 3/ 5], Step : [ 600/ 600], Loss: 0.2516\n",
      "Epoch : [ 4/ 5], Step : [ 100/ 600], Loss: 0.1561\n",
      "Epoch : [ 4/ 5], Step : [ 200/ 600], Loss: 0.4995\n",
      "Epoch : [ 4/ 5], Step : [ 300/ 600], Loss: 0.1943\n",
      "Epoch : [ 4/ 5], Step : [ 400/ 600], Loss: 0.5286\n",
      "Epoch : [ 4/ 5], Step : [ 500/ 600], Loss: 0.2668\n",
      "Epoch : [ 4/ 5], Step : [ 600/ 600], Loss: 0.2244\n",
      "Epoch : [ 5/ 5], Step : [ 100/ 600], Loss: 0.4220\n",
      "Epoch : [ 5/ 5], Step : [ 200/ 600], Loss: 0.2676\n",
      "Epoch : [ 5/ 5], Step : [ 300/ 600], Loss: 0.1943\n",
      "Epoch : [ 5/ 5], Step : [ 400/ 600], Loss: 0.1963\n",
      "Epoch : [ 5/ 5], Step : [ 500/ 600], Loss: 0.2673\n",
      "Epoch : [ 5/ 5], Step : [ 600/ 600], Loss: 0.2937\n"
     ]
    }
   ],
   "source": [
    "optimizer_test(optim_adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 10000 test images : 92 %\n"
     ]
    }
   ],
   "source": [
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [ 1/ 5], Step : [ 100/ 600], Loss: 0.3596\n",
      "Epoch : [ 1/ 5], Step : [ 200/ 600], Loss: 0.1396\n",
      "Epoch : [ 1/ 5], Step : [ 300/ 600], Loss: 0.2272\n",
      "Epoch : [ 1/ 5], Step : [ 400/ 600], Loss: 0.1554\n",
      "Epoch : [ 1/ 5], Step : [ 500/ 600], Loss: 0.2622\n",
      "Epoch : [ 1/ 5], Step : [ 600/ 600], Loss: 0.2111\n",
      "Epoch : [ 2/ 5], Step : [ 100/ 600], Loss: 0.1980\n",
      "Epoch : [ 2/ 5], Step : [ 200/ 600], Loss: 0.3810\n",
      "Epoch : [ 2/ 5], Step : [ 300/ 600], Loss: 0.3211\n",
      "Epoch : [ 2/ 5], Step : [ 400/ 600], Loss: 0.3223\n",
      "Epoch : [ 2/ 5], Step : [ 500/ 600], Loss: 0.2400\n",
      "Epoch : [ 2/ 5], Step : [ 600/ 600], Loss: 0.2899\n",
      "Epoch : [ 3/ 5], Step : [ 100/ 600], Loss: 0.1974\n",
      "Epoch : [ 3/ 5], Step : [ 200/ 600], Loss: 0.1348\n",
      "Epoch : [ 3/ 5], Step : [ 300/ 600], Loss: 0.2222\n",
      "Epoch : [ 3/ 5], Step : [ 400/ 600], Loss: 0.1992\n",
      "Epoch : [ 3/ 5], Step : [ 500/ 600], Loss: 0.1688\n",
      "Epoch : [ 3/ 5], Step : [ 600/ 600], Loss: 0.2416\n",
      "Epoch : [ 4/ 5], Step : [ 100/ 600], Loss: 0.2390\n",
      "Epoch : [ 4/ 5], Step : [ 200/ 600], Loss: 0.2289\n",
      "Epoch : [ 4/ 5], Step : [ 300/ 600], Loss: 0.4546\n",
      "Epoch : [ 4/ 5], Step : [ 400/ 600], Loss: 0.3112\n",
      "Epoch : [ 4/ 5], Step : [ 500/ 600], Loss: 0.2439\n",
      "Epoch : [ 4/ 5], Step : [ 600/ 600], Loss: 0.4008\n",
      "Epoch : [ 5/ 5], Step : [ 100/ 600], Loss: 0.2301\n",
      "Epoch : [ 5/ 5], Step : [ 200/ 600], Loss: 0.2856\n",
      "Epoch : [ 5/ 5], Step : [ 300/ 600], Loss: 0.1352\n",
      "Epoch : [ 5/ 5], Step : [ 400/ 600], Loss: 0.3216\n",
      "Epoch : [ 5/ 5], Step : [ 500/ 600], Loss: 0.1686\n",
      "Epoch : [ 5/ 5], Step : [ 600/ 600], Loss: 0.2300\n"
     ]
    }
   ],
   "source": [
    "optimizer_test(optim_rmsprop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 10000 test images : 92 %\n"
     ]
    }
   ],
   "source": [
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD + momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [ 1/ 5], Step : [ 100/ 600], Loss: 0.1673\n",
      "Epoch : [ 1/ 5], Step : [ 200/ 600], Loss: 0.2386\n",
      "Epoch : [ 1/ 5], Step : [ 300/ 600], Loss: 0.3361\n",
      "Epoch : [ 1/ 5], Step : [ 400/ 600], Loss: 0.3024\n",
      "Epoch : [ 1/ 5], Step : [ 500/ 600], Loss: 0.3362\n",
      "Epoch : [ 1/ 5], Step : [ 600/ 600], Loss: 0.3231\n",
      "Epoch : [ 2/ 5], Step : [ 100/ 600], Loss: 0.2595\n",
      "Epoch : [ 2/ 5], Step : [ 200/ 600], Loss: 0.3491\n",
      "Epoch : [ 2/ 5], Step : [ 300/ 600], Loss: 0.2047\n",
      "Epoch : [ 2/ 5], Step : [ 400/ 600], Loss: 0.1845\n",
      "Epoch : [ 2/ 5], Step : [ 500/ 600], Loss: 0.2680\n",
      "Epoch : [ 2/ 5], Step : [ 600/ 600], Loss: 0.4208\n",
      "Epoch : [ 3/ 5], Step : [ 100/ 600], Loss: 0.2037\n",
      "Epoch : [ 3/ 5], Step : [ 200/ 600], Loss: 0.3120\n",
      "Epoch : [ 3/ 5], Step : [ 300/ 600], Loss: 0.2362\n",
      "Epoch : [ 3/ 5], Step : [ 400/ 600], Loss: 0.3725\n",
      "Epoch : [ 3/ 5], Step : [ 500/ 600], Loss: 0.2053\n",
      "Epoch : [ 3/ 5], Step : [ 600/ 600], Loss: 0.1930\n",
      "Epoch : [ 4/ 5], Step : [ 100/ 600], Loss: 0.2133\n",
      "Epoch : [ 4/ 5], Step : [ 200/ 600], Loss: 0.2034\n",
      "Epoch : [ 4/ 5], Step : [ 300/ 600], Loss: 0.1740\n",
      "Epoch : [ 4/ 5], Step : [ 400/ 600], Loss: 0.3453\n",
      "Epoch : [ 4/ 5], Step : [ 500/ 600], Loss: 0.2339\n",
      "Epoch : [ 4/ 5], Step : [ 600/ 600], Loss: 0.1886\n",
      "Epoch : [ 5/ 5], Step : [ 100/ 600], Loss: 0.2153\n",
      "Epoch : [ 5/ 5], Step : [ 200/ 600], Loss: 0.2544\n",
      "Epoch : [ 5/ 5], Step : [ 300/ 600], Loss: 0.1304\n",
      "Epoch : [ 5/ 5], Step : [ 400/ 600], Loss: 0.3574\n",
      "Epoch : [ 5/ 5], Step : [ 500/ 600], Loss: 0.2840\n",
      "Epoch : [ 5/ 5], Step : [ 600/ 600], Loss: 0.2368\n"
     ]
    }
   ],
   "source": [
    "optimizer_test(optim_sgd_mom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 10000 test images : 92 %\n"
     ]
    }
   ],
   "source": [
    "test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
