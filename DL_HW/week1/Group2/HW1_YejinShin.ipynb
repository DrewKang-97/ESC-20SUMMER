{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H0 : False H1 : True일 때\n",
    "FP: 실제 False인 정답을 True라고 예측 (오답) -> Type 1 error\n",
    "FN: 실제 True인 정답을 False라고 예측 (오답) -> Type 2 error\n",
    "Type 1 error과 Type 2 error는 trade off 관계이다.\n",
    "따라서 FP와 FN 도 Trade off 관계에 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy(정확도: 전체 예측 중 옳게 말한 결과의 비율) = (TP+TN) / (TP+TN+FP+FN)\n",
    "Precision(정밀도: True라고 예측한 것 중 실제로 True의 비율) = TP / (TP+FP)\n",
    "Recall(재현율: 실제 True 중 True라고 예측한 것의 비율) = TP / (TP+FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "의사가 병의 진단을 내릴 때,\n",
    "H0: 병이 아니다, H1: 병이다\n",
    "이 경우, 병에 걸린 사람을 멀쩡하다고 진단하는 것을 막는 것이, 병에 걸리지 않은 사람이 위험하다고 진단하는 것을 막는 것보다 훨씬 중요하다.\n",
    "이 경우 threshold를 늘리는 것은 전자의 경우를 더 허용하는 것이므로 바람직하지 않다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torchvision.datasets as dsets \n",
    "import torchvision.transforms as transforms \n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e2c1f0c390>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For reproducibility \n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters  \n",
    "input_size = 784 # input size is 784\n",
    "num_classes = 10 # 10 digits are present in this and hence, we can have 10 different outputs\n",
    "num_epochs = 5 \n",
    "batch_size = 100 # will train in small batches of 100 images\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST Dataset (Images and Labels)  # 데이터셋 불러오기\n",
    "train_dataset = dsets.MNIST(root ='./data',  \n",
    "                            train = True,  \n",
    "                            transform = transforms.ToTensor(), \n",
    "                            download = True) \n",
    "\n",
    "test_dataset = dsets.MNIST(root ='./data',  \n",
    "                           train = False,  \n",
    "                           transform = transforms.ToTensor()) \n",
    "  \n",
    "# Dataset Loader (Input Pipline) \n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, # from torch.utils.data import Dataset \n",
    "                                           batch_size = batch_size, # 각 minibatch의 크기, 통상적으로 2의 제곱수로 설정\n",
    "                                           shuffle = True)          # Epoch마다 데이터셋을 섞어서, 데이터가 학습되는 순서를 바꾼다\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,  \n",
    "                                          batch_size = batch_size,  \n",
    "                                          shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module): # 무슨 모델 이용할 건지 정하기\n",
    "    def __init__(self, input_size, num_classes): \n",
    "        super(LogisticRegression, self).__init__() \n",
    "        self.linear = nn.Linear(input_size, num_classes) # 선형 모델\n",
    "  \n",
    "    def forward(self, x): # define the forward pass\n",
    "        out = self.linear(x) \n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(input_size, num_classes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() # loss function\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate) # optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 1/ 5], Step: [ 100/ 600], Loss: 2.2144\n",
      "Epoch: [ 1/ 5], Step: [ 200/ 600], Loss: 2.1163\n",
      "Epoch: [ 1/ 5], Step: [ 300/ 600], Loss: 2.0258\n",
      "Epoch: [ 1/ 5], Step: [ 400/ 600], Loss: 1.9763\n",
      "Epoch: [ 1/ 5], Step: [ 500/ 600], Loss: 1.9312\n",
      "Epoch: [ 1/ 5], Step: [ 600/ 600], Loss: 1.7738\n",
      "Epoch: [ 2/ 5], Step: [ 100/ 600], Loss: 1.7256\n",
      "Epoch: [ 2/ 5], Step: [ 200/ 600], Loss: 1.6739\n",
      "Epoch: [ 2/ 5], Step: [ 300/ 600], Loss: 1.6204\n",
      "Epoch: [ 2/ 5], Step: [ 400/ 600], Loss: 1.5783\n",
      "Epoch: [ 2/ 5], Step: [ 500/ 600], Loss: 1.5544\n",
      "Epoch: [ 2/ 5], Step: [ 600/ 600], Loss: 1.4273\n",
      "Epoch: [ 3/ 5], Step: [ 100/ 600], Loss: 1.4927\n",
      "Epoch: [ 3/ 5], Step: [ 200/ 600], Loss: 1.3208\n",
      "Epoch: [ 3/ 5], Step: [ 300/ 600], Loss: 1.3455\n",
      "Epoch: [ 3/ 5], Step: [ 400/ 600], Loss: 1.4228\n",
      "Epoch: [ 3/ 5], Step: [ 500/ 600], Loss: 1.3079\n",
      "Epoch: [ 3/ 5], Step: [ 600/ 600], Loss: 1.3068\n",
      "Epoch: [ 4/ 5], Step: [ 100/ 600], Loss: 1.2157\n",
      "Epoch: [ 4/ 5], Step: [ 200/ 600], Loss: 1.1718\n",
      "Epoch: [ 4/ 5], Step: [ 300/ 600], Loss: 1.2590\n",
      "Epoch: [ 4/ 5], Step: [ 400/ 600], Loss: 1.1482\n",
      "Epoch: [ 4/ 5], Step: [ 500/ 600], Loss: 1.1105\n",
      "Epoch: [ 4/ 5], Step: [ 600/ 600], Loss: 1.0919\n",
      "Epoch: [ 5/ 5], Step: [ 100/ 600], Loss: 1.1455\n",
      "Epoch: [ 5/ 5], Step: [ 200/ 600], Loss: 1.0963\n",
      "Epoch: [ 5/ 5], Step: [ 300/ 600], Loss: 0.9964\n",
      "Epoch: [ 5/ 5], Step: [ 400/ 600], Loss: 1.0458\n",
      "Epoch: [ 5/ 5], Step: [ 500/ 600], Loss: 1.1051\n",
      "Epoch: [ 5/ 5], Step: [ 600/ 600], Loss: 1.0592\n"
     ]
    }
   ],
   "source": [
    "# Training the Model \n",
    "for epoch in range(num_epochs): \n",
    "    for i, (images, labels) in enumerate(train_loader): \n",
    "        images = Variable(images.view(-1, 28 * 28)) \n",
    "        labels = Variable(labels) \n",
    "  \n",
    "        # Forward + Backward + Optimize \n",
    "        optimizer.zero_grad() # Reset all gradients to 0 (0으로 초기화)\n",
    "        outputs = model(images) # Make a forward pass (첫 예측)\n",
    "        loss = criterion(outputs, labels) # Calculate the loss (loss 어떻게 계산할 건지)\n",
    "        loss.backward() # Perform backpropagation (계산)\n",
    "        optimizer.step() # Update all weights\n",
    "  \n",
    "        if (i + 1) % 100 == 0: \n",
    "            print('Epoch: [% d/% d], Step: [% d/% d], Loss: %.4f'\n",
    "                  % (epoch + 1, num_epochs, i + 1, \n",
    "                     len(train_dataset) // batch_size, loss.data)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 10000 test images:  82 %\n"
     ]
    }
   ],
   "source": [
    "# Test the Model \n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader: \n",
    "    images = Variable(images.view(-1, 28 * 28))\n",
    "    outputs = model(images) \n",
    "    _, predicted = torch.max(outputs.data, 1) # ㅡmax 의 label 로 predict\n",
    "    total += labels.size(0) \n",
    "    correct += (predicted == labels).sum() \n",
    "    \n",
    "print('Accuracy of the model on the 10000 test images: % d %%' % ( \n",
    "            100 * correct / total)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 모르겠다 왜 알아야 하지.. SGD를 사용하지 못하는 경우가 있나?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터\n",
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[1], [2], [3]])\n",
    "\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(1, 1) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 W: 0.578, b: -0.413 Cost: 2.147149\n",
      "Epoch  100/1000 W: 1.066, b: -0.150 Cost: 0.003239\n",
      "Epoch  200/1000 W: 1.052, b: -0.118 Cost: 0.002002\n",
      "Epoch  300/1000 W: 1.041, b: -0.093 Cost: 0.001237\n",
      "Epoch  400/1000 W: 1.032, b: -0.073 Cost: 0.000764\n",
      "Epoch  500/1000 W: 1.025, b: -0.057 Cost: 0.000472\n",
      "Epoch  600/1000 W: 1.020, b: -0.045 Cost: 0.000292\n",
      "Epoch  700/1000 W: 1.016, b: -0.035 Cost: 0.000180\n",
      "Epoch  800/1000 W: 1.012, b: -0.028 Cost: 0.000111\n",
      "Epoch  900/1000 W: 1.010, b: -0.022 Cost: 0.000069\n",
      "Epoch 1000/1000 W: 1.008, b: -0.017 Cost: 0.000043\n"
     ]
    }
   ],
   "source": [
    "# For reproducibility \n",
    "torch.manual_seed(1)\n",
    "\n",
    "# 모델 초기화 \n",
    "model = LinearRegressionModel() \n",
    "W=torch.zeros(1)\n",
    "b=torch.zeros(1)\n",
    "\n",
    "# optimizer 설정 \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01) \n",
    "nb_epochs = 1000 \n",
    "\n",
    "for epoch in range(nb_epochs + 1):        \n",
    "\n",
    "    # H(x) 계산    \n",
    "    prediction = model(x_train)        \n",
    "\n",
    "    # cost 계산    \n",
    "    cost = F.mse_loss(prediction, y_train)        \n",
    "\n",
    "    # cost로 H(x) 개선    \n",
    "    optimizer.zero_grad() # 미분값이     \n",
    "    cost.backward()    \n",
    "    optimizer.step()        \n",
    "\n",
    "    # 100번마다 로그 출력    \n",
    "    if epoch % 100 == 0:        \n",
    "        params = list(model.parameters())        \n",
    "        W = params[0].item()        \n",
    "        b = params[1].item()        \n",
    "        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, W, b, cost.item()        \n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 W: 0.525, b: -0.431 Cost: 2.147149\n",
      "Epoch  100/1000 W: 0.992, b: 0.032 Cost: 0.000333\n",
      "Epoch  200/1000 W: 0.990, b: 0.022 Cost: 0.000072\n",
      "Epoch  300/1000 W: 0.993, b: 0.017 Cost: 0.000040\n",
      "Epoch  400/1000 W: 0.995, b: 0.012 Cost: 0.000020\n",
      "Epoch  500/1000 W: 0.997, b: 0.008 Cost: 0.000008\n",
      "Epoch  600/1000 W: 0.998, b: 0.005 Cost: 0.000003\n",
      "Epoch  700/1000 W: 0.999, b: 0.003 Cost: 0.000001\n",
      "Epoch  800/1000 W: 0.999, b: 0.002 Cost: 0.000000\n",
      "Epoch  900/1000 W: 1.000, b: 0.001 Cost: 0.000000\n",
      "Epoch 1000/1000 W: 1.000, b: 0.000 Cost: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# For reproducibility \n",
    "torch.manual_seed(1)\n",
    "\n",
    "# 모델 초기화 \n",
    "model = LinearRegressionModel() \n",
    "W=torch.zeros(1)\n",
    "b=torch.zeros(1)\n",
    "\n",
    "# optimizer 설정 \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01) \n",
    "nb_epochs = 1000 \n",
    "\n",
    "for epoch in range(nb_epochs + 1):        \n",
    "\n",
    "    # H(x) 계산    \n",
    "    prediction = model(x_train)        \n",
    "\n",
    "    # cost 계산    \n",
    "    cost = F.mse_loss(prediction, y_train)        \n",
    "\n",
    "    # cost로 H(x) 개선    \n",
    "    optimizer.zero_grad() # 미분값이     \n",
    "    cost.backward()    \n",
    "    optimizer.step()        \n",
    "\n",
    "    # 100번마다 로그 출력    \n",
    "    if epoch % 100 == 0:        \n",
    "        params = list(model.parameters())        \n",
    "        W = params[0].item()        \n",
    "        b = params[1].item()        \n",
    "        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, W, b, cost.item()        \n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rmsprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 W: 0.615, b: -0.341 Cost: 2.147149\n",
      "Epoch  100/1000 W: 0.992, b: 0.019 Cost: 0.000052\n",
      "Epoch  200/1000 W: 0.996, b: 0.008 Cost: 0.000010\n",
      "Epoch  300/1000 W: 0.999, b: 0.002 Cost: 0.000001\n",
      "Epoch  400/1000 W: 1.000, b: 0.000 Cost: 0.000000\n",
      "Epoch  500/1000 W: 1.000, b: 0.000 Cost: 0.000000\n",
      "Epoch  600/1000 W: 1.000, b: -0.000 Cost: 0.000000\n",
      "Epoch  700/1000 W: 0.984, b: -0.016 Cost: 0.002620\n",
      "Epoch  800/1000 W: 0.999, b: -0.001 Cost: 0.000006\n",
      "Epoch  900/1000 W: 0.998, b: -0.002 Cost: 0.000030\n",
      "Epoch 1000/1000 W: 0.996, b: -0.004 Cost: 0.000109\n"
     ]
    }
   ],
   "source": [
    "# For reproducibility \n",
    "torch.manual_seed(1)\n",
    "\n",
    "# 모델 초기화 \n",
    "model = LinearRegressionModel() \n",
    "W=torch.zeros(1)\n",
    "b=torch.zeros(1)\n",
    "\n",
    "# optimizer 설정 \n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.01) \n",
    "nb_epochs = 1000 \n",
    "\n",
    "for epoch in range(nb_epochs + 1):        \n",
    "\n",
    "    # H(x) 계산    \n",
    "    prediction = model(x_train)        \n",
    "\n",
    "    # cost 계산    \n",
    "    cost = F.mse_loss(prediction, y_train)        \n",
    "\n",
    "    # cost로 H(x) 개선    \n",
    "    optimizer.zero_grad() # 미분값이     \n",
    "    cost.backward()    \n",
    "    optimizer.step()        \n",
    "\n",
    "    # 100번마다 로그 출력    \n",
    "    if epoch % 100 == 0:        \n",
    "        params = list(model.parameters())        \n",
    "        W = params[0].item()        \n",
    "        b = params[1].item()        \n",
    "        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, W, b, cost.item()        \n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD with momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 W: 0.578, b: -0.413 Cost: 2.147149\n",
      "Epoch  100/1000 W: 1.007, b: -0.008 Cost: 0.000053\n",
      "Epoch  200/1000 W: 1.000, b: -0.000 Cost: 0.000000\n",
      "Epoch  300/1000 W: 1.000, b: -0.000 Cost: 0.000000\n",
      "Epoch  400/1000 W: 1.000, b: -0.000 Cost: 0.000000\n",
      "Epoch  500/1000 W: 1.000, b: -0.000 Cost: 0.000000\n",
      "Epoch  600/1000 W: 1.000, b: -0.000 Cost: 0.000000\n",
      "Epoch  700/1000 W: 1.000, b: -0.000 Cost: 0.000000\n",
      "Epoch  800/1000 W: 1.000, b: -0.000 Cost: 0.000000\n",
      "Epoch  900/1000 W: 1.000, b: -0.000 Cost: 0.000000\n",
      "Epoch 1000/1000 W: 1.000, b: -0.000 Cost: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# For reproducibility \n",
    "torch.manual_seed(1)\n",
    "\n",
    "# 모델 초기화 \n",
    "model = LinearRegressionModel() \n",
    "W=torch.zeros(1)\n",
    "b=torch.zeros(1)\n",
    "\n",
    "# optimizer 설정 \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9) # 교차 검증할 거면 0.5, 0.9, 0.95, 0.99 순서로 증가시켜 검증\n",
    "nb_epochs = 1000 \n",
    "\n",
    "for epoch in range(nb_epochs + 1):        \n",
    "\n",
    "    # H(x) 계산    \n",
    "    prediction = model(x_train)        \n",
    "\n",
    "    # cost 계산    \n",
    "    cost = F.mse_loss(prediction, y_train)        \n",
    "\n",
    "    # cost로 H(x) 개선    \n",
    "    optimizer.zero_grad() # 미분값이     \n",
    "    cost.backward()    \n",
    "    optimizer.step()        \n",
    "\n",
    "    # 100번마다 로그 출력    \n",
    "    if epoch % 100 == 0:        \n",
    "        params = list(model.parameters())        \n",
    "        W = params[0].item()        \n",
    "        b = params[1].item()        \n",
    "        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, W, b, cost.item()        \n",
    "        ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
