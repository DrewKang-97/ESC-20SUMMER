{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020 SUMMER ESC :: Week 1 세션 과제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2020.07.26 김채형"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1) 이 경우에서는 Type 1 error 와 Type 2 Error 중 무엇이 더 높을까요? FP, FN과 관련지어 설명해주세요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 경우에서는 threshold가 낮아 FN이 낮고 FP가 높다. 이때 FN은 Type 1 error에 대응되고 FP는 Type 2 error에 대응되기 때문에 결과적으로 Type 1 error에 비해 Type 2 error가 더 높다고 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2-1) Accuracy, Precision and Recall이 무엇인지 TP, FP, TN, FN 의 식으로 나타내 주세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy = (TP + TN) / (TP + TN + FP + FN)  \n",
    "Precision = TP / (TP + FP)  \n",
    "Recall = TP / (TP + FN)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2-2) Precision & Recall 에 관한 예시 하나를 들어주세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FP의 위험성이 높은 분야에서는 Precision을 우선적으로, FN의 위험성이 높은 분야에서는 Recall을 우선적으로 사용하는 것이 일반적이다. 예를 들어, 우리가 사법 기관에서 무죄추정의 원칙을 기본으로 하는 것은 유죄인 사람이 무죄를 받는 것보다 무죄인 사람이 유죄를 받는 것에 더 초점을 맞추어 이를 방지하고자 하기 위함이다. 이러한 경우에는 Precision을 우선시 한다고 볼 수 있다. 반면 음주 운전 단속의 경우에는 실제로 음주 운전을 했는데 안 했다고 하는 것이 보다 더 위험하기 때문에 Recall을 우선적으로 고려할 필요가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3) 코드 따라해보고 주석 달기! \n",
    "\n",
    "[코드 출처](https://www.geeksforgeeks.org/identifying-handwritten-digits-using-logistic-regression-pytorch/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST Dataset (Images and Labels)\n",
    "train_dataset = dsets.MNIST(root = './data',\n",
    "                           train = True,\n",
    "                           transform = transforms.ToTensor(),\n",
    "                           download = True)\n",
    "test_dataset = dsets.MNIST(root = './data',\n",
    "                          train = False,\n",
    "                           transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "input_size = 784\n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Loader (Input Pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                          batch_size = batch_size, \n",
    "                                          shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                         batch_size = batch_size,\n",
    "                                         shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our model\n",
    "class LogisticRegression(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(input_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set our loss function & optimiser\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 1/ 5], Step: [ 100/ 600], Loss: 2.2049\n",
      "Epoch: [ 1/ 5], Step: [ 200/ 600], Loss: 2.1466\n",
      "Epoch: [ 1/ 5], Step: [ 300/ 600], Loss: 1.9971\n",
      "Epoch: [ 1/ 5], Step: [ 400/ 600], Loss: 1.9440\n",
      "Epoch: [ 1/ 5], Step: [ 500/ 600], Loss: 1.8824\n",
      "Epoch: [ 1/ 5], Step: [ 600/ 600], Loss: 1.8366\n",
      "Epoch: [ 2/ 5], Step: [ 100/ 600], Loss: 1.8027\n",
      "Epoch: [ 2/ 5], Step: [ 200/ 600], Loss: 1.7118\n",
      "Epoch: [ 2/ 5], Step: [ 300/ 600], Loss: 1.5711\n",
      "Epoch: [ 2/ 5], Step: [ 400/ 600], Loss: 1.5623\n",
      "Epoch: [ 2/ 5], Step: [ 500/ 600], Loss: 1.5053\n",
      "Epoch: [ 2/ 5], Step: [ 600/ 600], Loss: 1.3734\n",
      "Epoch: [ 3/ 5], Step: [ 100/ 600], Loss: 1.4168\n",
      "Epoch: [ 3/ 5], Step: [ 200/ 600], Loss: 1.4881\n",
      "Epoch: [ 3/ 5], Step: [ 300/ 600], Loss: 1.3270\n",
      "Epoch: [ 3/ 5], Step: [ 400/ 600], Loss: 1.2609\n",
      "Epoch: [ 3/ 5], Step: [ 500/ 600], Loss: 1.2020\n",
      "Epoch: [ 3/ 5], Step: [ 600/ 600], Loss: 1.2369\n",
      "Epoch: [ 4/ 5], Step: [ 100/ 600], Loss: 1.2416\n",
      "Epoch: [ 4/ 5], Step: [ 200/ 600], Loss: 1.1919\n",
      "Epoch: [ 4/ 5], Step: [ 300/ 600], Loss: 1.1171\n",
      "Epoch: [ 4/ 5], Step: [ 400/ 600], Loss: 1.2222\n",
      "Epoch: [ 4/ 5], Step: [ 500/ 600], Loss: 1.1494\n",
      "Epoch: [ 4/ 5], Step: [ 600/ 600], Loss: 1.0734\n",
      "Epoch: [ 5/ 5], Step: [ 100/ 600], Loss: 1.0613\n",
      "Epoch: [ 5/ 5], Step: [ 200/ 600], Loss: 1.0504\n",
      "Epoch: [ 5/ 5], Step: [ 300/ 600], Loss: 1.0025\n",
      "Epoch: [ 5/ 5], Step: [ 400/ 600], Loss: 1.0843\n",
      "Epoch: [ 5/ 5], Step: [ 500/ 600], Loss: 1.0569\n",
      "Epoch: [ 5/ 5], Step: [ 600/ 600], Loss: 0.9068\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images.view(-1, 28*28))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad() # 1. Reset all gradients to 0\n",
    "        outputs = model(images) # 2. Make a forward pass\n",
    "        loss = criterion(outputs, labels) # 3. Calculate the loss\n",
    "        loss.backward() # 4. Perform backpropagation\n",
    "        optimizer.step() # 5. Update all weights\n",
    "        \n",
    "        if (i + 1) % 100 == 0: \n",
    "            print('Epoch: [% d/% d], Step: [% d/% d], Loss: %.4f'\n",
    "                  % (epoch+1, num_epochs, i+1, len(train_dataset) // batch_size, loss.data)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 10000 test images:  82 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/distiller/project/conda/conda-bld/pytorch_1591914925853/work/aten/src/ATen/native/BinaryOps.cpp:81: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = Variable(images.view(-1, 28*28))\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted==labels).sum()\n",
    "print('Accuracy of the model on the 10000 test images: % d %%'\n",
    "      % (100*correct/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4-1) 2-4 코드에서 optim.SGD를 사용하지않고 코드를 짠다면 어떤 방식으로 짜야할지 설명해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tgrad:  tensor([1.]) tensor([2.]) -2.0\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -7.840000152587891\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -16.228801727294922\n",
      "Epoch: 0 | Loss: 7.315943717956543\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -1.478623867034912\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -5.796205520629883\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -11.998146057128906\n",
      "Epoch: 1 | Loss: 3.9987640380859375\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -1.0931644439697266\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -4.285204887390137\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -8.870372772216797\n",
      "Epoch: 2 | Loss: 2.1856532096862793\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -0.8081896305084229\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -3.1681032180786133\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -6.557973861694336\n",
      "Epoch: 3 | Loss: 1.1946394443511963\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -0.5975041389465332\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.3422164916992188\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -4.848389625549316\n",
      "Epoch: 4 | Loss: 0.6529689431190491\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -0.4417421817779541\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -1.7316293716430664\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -3.58447265625\n",
      "Epoch: 5 | Loss: 0.35690122842788696\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -0.3265852928161621\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -1.2802143096923828\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -2.650045394897461\n",
      "Epoch: 6 | Loss: 0.195076122879982\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -0.24144840240478516\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -0.9464778900146484\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -1.9592113494873047\n",
      "Epoch: 7 | Loss: 0.10662525147199631\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -0.17850565910339355\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -0.699742317199707\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -1.4484672546386719\n",
      "Epoch: 8 | Loss: 0.0582793727517128\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -0.1319713592529297\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -0.5173273086547852\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -1.070866584777832\n",
      "Epoch: 9 | Loss: 0.03185431286692619\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -0.09756779670715332\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -0.3824653625488281\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -0.7917022705078125\n",
      "Epoch: 10 | Loss: 0.017410902306437492\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -0.07213282585144043\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -0.2827606201171875\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -0.5853137969970703\n",
      "Epoch: 11 | Loss: 0.009516451507806778\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -0.053328514099121094\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -0.2090473175048828\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -0.43272972106933594\n",
      "Epoch: 12 | Loss: 0.005201528314501047\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -0.039426326751708984\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -0.15455150604248047\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -0.3199195861816406\n",
      "Epoch: 13 | Loss: 0.0028430151287466288\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -0.029148340225219727\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -0.11426162719726562\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -0.23652076721191406\n",
      "Epoch: 14 | Loss: 0.0015539465239271522\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -0.021549701690673828\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -0.08447456359863281\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -0.17486286163330078\n",
      "Epoch: 15 | Loss: 0.0008493617060594261\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -0.01593184471130371\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -0.062453269958496094\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -0.12927818298339844\n",
      "Epoch: 16 | Loss: 0.00046424579340964556\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -0.011778593063354492\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -0.046172142028808594\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -0.09557533264160156\n",
      "Epoch: 17 | Loss: 0.0002537401160225272\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -0.00870823860168457\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -0.03413581848144531\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -0.07066154479980469\n",
      "Epoch: 18 | Loss: 0.00013869594840798527\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -0.006437778472900391\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -0.025236129760742188\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -0.052239418029785156\n",
      "Epoch: 19 | Loss: 7.580435340059921e-05\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -0.004759550094604492\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -0.018657684326171875\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -0.038620948791503906\n",
      "Epoch: 20 | Loss: 4.143271507928148e-05\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -0.003518819808959961\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -0.0137939453125\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -0.028553009033203125\n",
      "Epoch: 21 | Loss: 2.264650902361609e-05\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -0.00260162353515625\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -0.010198593139648438\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -0.021108627319335938\n",
      "Epoch: 22 | Loss: 1.2377059647405986e-05\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -0.0019233226776123047\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -0.0075397491455078125\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -0.0156097412109375\n",
      "Epoch: 23 | Loss: 6.768445018678904e-06\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -0.0014221668243408203\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -0.0055751800537109375\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -0.011541366577148438\n",
      "Epoch: 24 | Loss: 3.7000872907810844e-06\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -0.0010514259338378906\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -0.0041217803955078125\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -0.008531570434570312\n",
      "Epoch: 25 | Loss: 2.021880391112063e-06\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -0.0007772445678710938\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -0.0030469894409179688\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -0.006305694580078125\n",
      "Epoch: 26 | Loss: 1.1044940038118511e-06\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -0.0005745887756347656\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -0.0022525787353515625\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -0.0046634674072265625\n",
      "Epoch: 27 | Loss: 6.041091182851233e-07\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -0.0004248619079589844\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -0.0016651153564453125\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -0.003444671630859375\n",
      "Epoch: 28 | Loss: 3.296045179013163e-07\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -0.0003139972686767578\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -0.0012311935424804688\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -0.0025491714477539062\n",
      "Epoch: 29 | Loss: 1.805076408345485e-07\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -0.00023221969604492188\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -0.0009107589721679688\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -0.0018854141235351562\n",
      "Epoch: 30 | Loss: 9.874406714516226e-08\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -0.00017189979553222656\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -0.0006742477416992188\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -0.00139617919921875\n",
      "Epoch: 31 | Loss: 5.4147676564753056e-08\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -0.0001270771026611328\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -0.0004978179931640625\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -0.00102996826171875\n",
      "Epoch: 32 | Loss: 2.9467628337442875e-08\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -9.393692016601562e-05\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -0.0003681182861328125\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -0.0007610321044921875\n",
      "Epoch: 33 | Loss: 1.6088051779661328e-08\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -6.937980651855469e-05\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -0.00027179718017578125\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -0.000560760498046875\n",
      "Epoch: 34 | Loss: 8.734787115827203e-09\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -5.125999450683594e-05\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -0.00020122528076171875\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -0.0004177093505859375\n",
      "Epoch: 35 | Loss: 4.8466972657479346e-09\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -3.790855407714844e-05\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -0.000148773193359375\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -0.000308990478515625\n",
      "Epoch: 36 | Loss: 2.6520865503698587e-09\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -2.8133392333984375e-05\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -0.000110626220703125\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -0.0002288818359375\n",
      "Epoch: 37 | Loss: 1.4551915228366852e-09\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -2.09808349609375e-05\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -8.20159912109375e-05\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -0.00016880035400390625\n",
      "Epoch: 38 | Loss: 7.914877642178908e-10\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -1.5497207641601562e-05\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -6.103515625e-05\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -0.000125885009765625\n",
      "Epoch: 39 | Loss: 4.4019543565809727e-10\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -1.1444091796875e-05\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -4.482269287109375e-05\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -9.1552734375e-05\n",
      "Epoch: 40 | Loss: 2.3283064365386963e-10\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -8.344650268554688e-06\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -3.24249267578125e-05\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -6.580352783203125e-05\n",
      "Epoch: 41 | Loss: 1.2028067430946976e-10\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -5.9604644775390625e-06\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.288818359375e-05\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -4.57763671875e-05\n",
      "Epoch: 42 | Loss: 5.820766091346741e-11\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -4.291534423828125e-06\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -1.71661376953125e-05\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -3.719329833984375e-05\n",
      "Epoch: 43 | Loss: 3.842615114990622e-11\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -3.337860107421875e-06\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -1.33514404296875e-05\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -2.86102294921875e-05\n",
      "Epoch: 44 | Loss: 2.2737367544323206e-11\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -2.6226043701171875e-06\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -1.049041748046875e-05\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -2.288818359375e-05\n",
      "Epoch: 45 | Loss: 1.4551915228366852e-11\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -1.9073486328125e-06\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -7.62939453125e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -1.430511474609375e-05\n",
      "Epoch: 46 | Loss: 5.6843418860808015e-12\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -1.430511474609375e-06\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -5.7220458984375e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -1.1444091796875e-05\n",
      "Epoch: 47 | Loss: 3.637978807091713e-12\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -1.1920928955078125e-06\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -4.76837158203125e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -1.1444091796875e-05\n",
      "Epoch: 48 | Loss: 3.637978807091713e-12\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -9.5367431640625e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -3.814697265625e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -8.58306884765625e-06\n",
      "Epoch: 49 | Loss: 2.0463630789890885e-12\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 50 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 51 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 52 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 53 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 54 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 55 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 56 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 57 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 58 | Loss: 9.094947017729282e-13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 59 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 60 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 61 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 62 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 63 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 64 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 65 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 66 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 67 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 68 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 69 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 70 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 71 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 72 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 73 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 74 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 75 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 76 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 77 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 78 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 79 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 80 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 81 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 82 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 83 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 84 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 85 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 86 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 87 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 88 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 89 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 90 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 91 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 92 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 93 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 94 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 95 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 96 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 97 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 98 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 99 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 100 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 101 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 102 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 103 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 104 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 105 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 106 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 107 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 108 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 109 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 110 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 111 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 112 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 113 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 114 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 115 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 116 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 117 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 118 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 119 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 120 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 121 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 122 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 123 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 124 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 125 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 126 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 127 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 128 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 129 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 130 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 131 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 132 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 133 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 134 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 135 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 136 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 137 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 138 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 139 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 140 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 141 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 142 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 143 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 144 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 145 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 146 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 147 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 148 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 149 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 150 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 151 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 152 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 153 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 154 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 155 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 156 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 157 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 158 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 159 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 160 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 161 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 162 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 163 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 164 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 165 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 166 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 167 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 168 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 169 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 170 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 171 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 172 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 173 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 174 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 175 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 176 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 177 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 178 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 179 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 180 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 181 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 182 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 183 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 184 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 185 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 186 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 187 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 188 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 189 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 190 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 191 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 192 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 193 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 194 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 195 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 196 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 197 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 198 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 199 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 200 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 201 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 202 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 203 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 204 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 205 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 206 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 207 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 208 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 209 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 210 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 211 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 212 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 213 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 214 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 215 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 216 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 217 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 218 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 219 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 220 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 221 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 222 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 223 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 224 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 225 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 226 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 227 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 228 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 229 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 230 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 231 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 232 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 233 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 234 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 235 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 236 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 237 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 238 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 239 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 240 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 241 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 242 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 243 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 244 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 245 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 246 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 247 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 248 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 249 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 250 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 251 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 252 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 253 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 254 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 255 | Loss: 9.094947017729282e-13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 256 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 257 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 258 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 259 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 260 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 261 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 262 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 263 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 264 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 265 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 266 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 267 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 268 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 269 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 270 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 271 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 272 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 273 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 274 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 275 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 276 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 277 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 278 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 279 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 280 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 281 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 282 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 283 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 284 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 285 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 286 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 287 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 288 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 289 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 290 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 291 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 292 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 293 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 294 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 295 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 296 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 297 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 298 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 299 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 300 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 301 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 302 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 303 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 304 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 305 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 306 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 307 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 308 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 309 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 310 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 311 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 312 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 313 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 314 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 315 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 316 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 317 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 318 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 319 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 320 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 321 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 322 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 323 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 324 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 325 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 326 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 327 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 328 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 329 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 330 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 331 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 332 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 333 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 334 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 335 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 336 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 337 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 338 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 339 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 340 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 341 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 342 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 343 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 344 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 345 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 346 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 347 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 348 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 349 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 350 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 351 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 352 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 353 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 354 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 355 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 356 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 357 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 358 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 359 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 360 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 361 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 362 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 363 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 364 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 365 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 366 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 367 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 368 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 369 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 370 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 371 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 372 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 373 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 374 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 375 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 376 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 377 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 378 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 379 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 380 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 381 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 382 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 383 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 384 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 385 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 386 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 387 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 388 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 389 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 390 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 391 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 392 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 393 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 394 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 395 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 396 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 397 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 398 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 399 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 400 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 401 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 402 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 403 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 404 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 405 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 406 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 407 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 408 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 409 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 410 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 411 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 412 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 413 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 414 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 415 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 416 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 417 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 418 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 419 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 420 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 421 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 422 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 423 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 424 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 425 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 426 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 427 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 428 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 429 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 430 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 431 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 432 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 433 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 434 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 435 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 436 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 437 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 438 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 439 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 440 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 441 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 442 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 443 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 444 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 445 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 446 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 447 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 448 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 449 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 450 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 451 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 452 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 453 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 454 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 455 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 456 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 457 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 458 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 459 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 460 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 461 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 462 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 463 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 464 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 465 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 466 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 467 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 468 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 469 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 470 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 471 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 472 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 473 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 474 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 475 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 476 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 477 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 478 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 479 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 480 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 481 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 482 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 483 | Loss: 9.094947017729282e-13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 484 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 485 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 486 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 487 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 488 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 489 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 490 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 491 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 492 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 493 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 494 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 495 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 496 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 497 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 498 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 499 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 500 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 501 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 502 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 503 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 504 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 505 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 506 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 507 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 508 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 509 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 510 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 511 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 512 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 513 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 514 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 515 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 516 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 517 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 518 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 519 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 520 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 521 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 522 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 523 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 524 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 525 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 526 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 527 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 528 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 529 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 530 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 531 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 532 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 533 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 534 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 535 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 536 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 537 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 538 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 539 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 540 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 541 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 542 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 543 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 544 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 545 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 546 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 547 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 548 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 549 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 550 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 551 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 552 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 553 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 554 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 555 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 556 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 557 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 558 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 559 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 560 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 561 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 562 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 563 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 564 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 565 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 566 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 567 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 568 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 569 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 570 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 571 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 572 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 573 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 574 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 575 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 576 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 577 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 578 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 579 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 580 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 581 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 582 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 583 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 584 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 585 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 586 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 587 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 588 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 589 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 590 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 591 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 592 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 593 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 594 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 595 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 596 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 597 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 598 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 599 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 600 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 601 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 602 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 603 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 604 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 605 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 606 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 607 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 608 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 609 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 610 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 611 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 612 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 613 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 614 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 615 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 616 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 617 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 618 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 619 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 620 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 621 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 622 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 623 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 624 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 625 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 626 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 627 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 628 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 629 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 630 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 631 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 632 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 633 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 634 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 635 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 636 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 637 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 638 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 639 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 640 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 641 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 642 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 643 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 644 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 645 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 646 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 647 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 648 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 649 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 650 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 651 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 652 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 653 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 654 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 655 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 656 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 657 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 658 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 659 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 660 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 661 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 662 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 663 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 664 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 665 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 666 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 667 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 668 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 669 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 670 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 671 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 672 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 673 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 674 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 675 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 676 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 677 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 678 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 679 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 680 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 681 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 682 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 683 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 684 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 685 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 686 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 687 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 688 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 689 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 690 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 691 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 692 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 693 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 694 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 695 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 696 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 697 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 698 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 699 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 700 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 701 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 702 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 703 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 704 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 705 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 706 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 707 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 708 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 709 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 710 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 711 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 712 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 713 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 714 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 715 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 716 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 717 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 718 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 719 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 720 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 721 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 722 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 723 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 724 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 725 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 726 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 727 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 728 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 729 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 730 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 731 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 732 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 733 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 734 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 735 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 736 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 737 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 738 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 739 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 740 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 741 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 742 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 743 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 744 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 745 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 746 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 747 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 748 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 749 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 750 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 751 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 752 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 753 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 754 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 755 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 756 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 757 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 758 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 759 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 760 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 761 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 762 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 763 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 764 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 765 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 766 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 767 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 768 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 769 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 770 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 771 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 772 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 773 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 774 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 775 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 776 | Loss: 9.094947017729282e-13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 777 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 778 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 779 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 780 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 781 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 782 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 783 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 784 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 785 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 786 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 787 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 788 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 789 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 790 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 791 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 792 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 793 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 794 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 795 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 796 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 797 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 798 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 799 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 800 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 801 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 802 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 803 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 804 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 805 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 806 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 807 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 808 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 809 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 810 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 811 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 812 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 813 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 814 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 815 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 816 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 817 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 818 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 819 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 820 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 821 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 822 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 823 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 824 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 825 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 826 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 827 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 828 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 829 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 830 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 831 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 832 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 833 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 834 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 835 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 836 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 837 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 838 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 839 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 840 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 841 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 842 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 843 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 844 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 845 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 846 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 847 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 848 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 849 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 850 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 851 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 852 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 853 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 854 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 855 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 856 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 857 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 858 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 859 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 860 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 861 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 862 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 863 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 864 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 865 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 866 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 867 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 868 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 869 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 870 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 871 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 872 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 873 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 874 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 875 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 876 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 877 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 878 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 879 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 880 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 881 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 882 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 883 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 884 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 885 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 886 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 887 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 888 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 889 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 890 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 891 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 892 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 893 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 894 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 895 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 896 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 897 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 898 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 899 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 900 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 901 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 902 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 903 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 904 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 905 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 906 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 907 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 908 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 909 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 910 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 911 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 912 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 913 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 914 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 915 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 916 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 917 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 918 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 919 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 920 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 921 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 922 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 923 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 924 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 925 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 926 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 927 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 928 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 929 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 930 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 931 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 932 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 933 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 934 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 935 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 936 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 937 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 938 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 939 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 940 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 941 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 942 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 943 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 944 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 945 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 946 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 947 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 948 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 949 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 950 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 951 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 952 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 953 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 954 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 955 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 956 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 957 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 958 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 959 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 960 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 961 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 962 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 963 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 964 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 965 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 966 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 967 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 968 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 969 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 970 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 971 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 972 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 973 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 974 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 975 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 976 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 977 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 978 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 979 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 980 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 981 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 982 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 983 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 984 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 985 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 986 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 987 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 988 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 989 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 990 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 991 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 992 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 993 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 994 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 995 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 996 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 997 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 998 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 999 | Loss: 9.094947017729282e-13\n",
      "\tgrad:  tensor([1.]) tensor([2.]) -7.152557373046875e-07\n",
      "\tgrad:  tensor([2.]) tensor([4.]) -2.86102294921875e-06\n",
      "\tgrad:  tensor([3.]) tensor([6.]) -5.7220458984375e-06\n",
      "Epoch: 1000 | Loss: 9.094947017729282e-13\n"
     ]
    }
   ],
   "source": [
    "# Generate dataset\n",
    "x_data = tensor([[1.0], [2.0], [3.0]])\n",
    "y_data = tensor([[2.0], [4.0], [6.0]])\n",
    "w = torch.tensor([1.0], requires_grad=True)\n",
    "\n",
    "# Define forward pass\n",
    "def forward(x):\n",
    "    return x*w\n",
    "\n",
    "# Define loss function\n",
    "def loss(y_pred, y_val):\n",
    "    return (y_pred-y_val)**2\n",
    "\n",
    "# Training loop\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs+1):\n",
    "    for x_val, y_val in zip(x_data, y_data):\n",
    "        \n",
    "        y_pred = forward(x_val) # Forward pass\n",
    "        l = loss(y_pred, y_val) # Loss\n",
    "        l.backward() # Back propagation\n",
    "        \n",
    "        print('\\tgrad: ', x_val, y_val, w.grad.item())\n",
    "        \n",
    "        w.data = w.data - 0.01*w.grad.item() # w 업데이트\n",
    "        w.grad.data.zero_() # w 초기화\n",
    "\n",
    "    print(f'Epoch: {epoch} | Loss: {l.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4-2) Gradient descent 코드를 구현하는 문제입니다. 2-4의 코드에서 다른 optimizer 3개를 이용하여 결과값을 비교해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RMSprop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 W: -0.193, b: 0.788 Cost: 4.714807\n",
      "Epoch  100/1000 W: 0.518, b: 1.063 Cost: 0.165974\n",
      "Epoch  200/1000 W: 0.694, b: 0.678 Cost: 0.067547\n",
      "Epoch  300/1000 W: 0.850, b: 0.333 Cost: 0.016410\n",
      "Epoch  400/1000 W: 0.952, b: 0.106 Cost: 0.001692\n",
      "Epoch  500/1000 W: 0.993, b: 0.016 Cost: 0.000040\n",
      "Epoch  600/1000 W: 1.000, b: 0.001 Cost: 0.000000\n",
      "Epoch  700/1000 W: 1.000, b: 0.000 Cost: 0.000000\n",
      "Epoch  800/1000 W: 1.000, b: 0.000 Cost: 0.000000\n",
      "Epoch  900/1000 W: 1.007, b: 0.007 Cost: 0.000265\n",
      "Epoch 1000/1000 W: 1.002, b: 0.002 Cost: 0.000043\n"
     ]
    }
   ],
   "source": [
    "# 데이터\n",
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[1], [2], [3]])\n",
    "\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "    \n",
    "# 모델 초기화\n",
    "model = LinearRegressionModel()\n",
    "\n",
    "# optimizer 설정\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.01)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    \n",
    "    # H(x) 계산\n",
    "    prediction = model(x_train)\n",
    "    \n",
    "    # cost 계산\n",
    "    cost = F.mse_loss(prediction, y_train)\n",
    "    \n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 100번마다 로그 출력\n",
    "    if epoch % 100 == 0:\n",
    "        params = list(model.parameters())\n",
    "        W = params[0].item()\n",
    "        b = params[1].item()\n",
    "        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, W, b, cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adam**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 W: -0.053, b: 0.846 Cost: 2.420716\n",
      "Epoch  100/1000 W: 0.461, b: 1.204 Cost: 0.210404\n",
      "Epoch  200/1000 W: 0.569, b: 0.952 Cost: 0.132647\n",
      "Epoch  300/1000 W: 0.682, b: 0.702 Cost: 0.072211\n",
      "Epoch  400/1000 W: 0.780, b: 0.485 Cost: 0.034513\n",
      "Epoch  500/1000 W: 0.857, b: 0.315 Cost: 0.014580\n",
      "Epoch  600/1000 W: 0.913, b: 0.193 Cost: 0.005456\n",
      "Epoch  700/1000 W: 0.950, b: 0.111 Cost: 0.001809\n",
      "Epoch  800/1000 W: 0.973, b: 0.060 Cost: 0.000530\n",
      "Epoch  900/1000 W: 0.986, b: 0.030 Cost: 0.000137\n",
      "Epoch 1000/1000 W: 0.993, b: 0.015 Cost: 0.000031\n"
     ]
    }
   ],
   "source": [
    "# 데이터\n",
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[1], [2], [3]])\n",
    "\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "    \n",
    "# 모델 초기화\n",
    "model = LinearRegressionModel()\n",
    "\n",
    "# optimizer 설정\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    \n",
    "    # H(x) 계산\n",
    "    prediction = model(x_train)\n",
    "    \n",
    "    # cost 계산\n",
    "    cost = F.mse_loss(prediction, y_train)\n",
    "    \n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 100번마다 로그 출력\n",
    "    if epoch % 100 == 0:\n",
    "        params = list(model.parameters())\n",
    "        W = params[0].item()\n",
    "        b = params[1].item()\n",
    "        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, W, b, cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adadelta**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 W: -0.208, b: 0.715 Cost: 3.867588\n",
      "Epoch  100/1000 W: -0.204, b: 0.719 Cost: 3.819863\n",
      "Epoch  200/1000 W: -0.199, b: 0.724 Cost: 3.759923\n",
      "Epoch  300/1000 W: -0.193, b: 0.730 Cost: 3.690643\n",
      "Epoch  400/1000 W: -0.186, b: 0.737 Cost: 3.613771\n",
      "Epoch  500/1000 W: -0.179, b: 0.744 Cost: 3.530621\n",
      "Epoch  600/1000 W: -0.171, b: 0.752 Cost: 3.442243\n",
      "Epoch  700/1000 W: -0.163, b: 0.761 Cost: 3.349527\n",
      "Epoch  800/1000 W: -0.154, b: 0.769 Cost: 3.253246\n",
      "Epoch  900/1000 W: -0.144, b: 0.779 Cost: 3.154080\n",
      "Epoch 1000/1000 W: -0.135, b: 0.788 Cost: 3.052647\n"
     ]
    }
   ],
   "source": [
    "# 데이터\n",
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[1], [2], [3]])\n",
    "\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "    \n",
    "# 모델 초기화\n",
    "model = LinearRegressionModel()\n",
    "\n",
    "# optimizer 설정\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=0.01)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    \n",
    "    # H(x) 계산\n",
    "    prediction = model(x_train)\n",
    "    \n",
    "    # cost 계산\n",
    "    cost = F.mse_loss(prediction, y_train)\n",
    "    \n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 100번마다 로그 출력\n",
    "    if epoch % 100 == 0:\n",
    "        params = list(model.parameters())\n",
    "        W = params[0].item()\n",
    "        b = params[1].item()\n",
    "        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, W, b, cost.item()\n",
    "        ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
