{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type 1 error는 false인 H0를 accept하는 것, 즉 FP 사건<br>\n",
    "Type 2 error는 true인 H0를 reject하는 것, 즉 FN 사건<br>\n",
    "<br>\n",
    "회원가입의 threshold가 낮은 경우는 FP rate가 높고 FN rate가 낮은 경우이기 때문에<br>\n",
    "Type 1 error 발생 가능성이 높은 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy(정확도) = $\\frac {TP + TN} {TP + FN + FP + TN}$<br>\n",
    "=> 전체 예측 중 True를 True로, False를 False로 옳게 예측한 비율<br>\n",
    "<br>\n",
    "Precision(정밀도) = $\\frac {TP} {TP + FP}$<br>\n",
    "=> True로 예측한 것 중 실제 True의 비율<br>\n",
    "<br>\n",
    "Recall(재현율) = $\\frac {TP} {TP + FN}$<br>\n",
    "=>실제 True 중 True로 예측한 것의 비율"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일기예보<br>\n",
    "<br>\n",
    "비가 오는 사건을 True라고 했을 때,<br>\n",
    "일기예보에서 비가 온다고 예측했는데 실제로 비가 온 날의 비율이 Precision,<br>\n",
    "실제로 비가 온 날 중 일기예보에서 비를 예측한 날의 비율이 Recall<br>\n",
    "<br>\n",
    "이 예시에서 성공확률의 threshold를 높인다는 건 일기예보의 비 예측을 믿지 않는 것이다<br>\n",
    "우산을 가지고 나갔는데 비가 안 오는 건 큰 상관이 없는 데 비해 비가 오는데 우산이 없는 건 대참사이므로 이 예시에서는 threshold를 높이는 것이 비합리적이다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MNIST dataset\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "train_dataset = MNIST(root='MNIST_data')\n",
    "test_dataset = MNIST(root='MNIST_data', train=False)\n",
    "\n",
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Image sample\n",
    "image, label = train_dataset[0]\n",
    "plt.imshow(image)\n",
    "print('Label:', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = train_dataset[10]\n",
    "plt.imshow(image)\n",
    "print('Label:', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform image to pytorch via ToTensor()\n",
    "train_dataset = MNIST(root='MNIST_data', train=True,\n",
    "                      transform=transforms.ToTensor())\n",
    "test_dataset = MNIST(root='MNIST_data', train=False,\n",
    "                      transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) 5\n"
     ]
    }
   ],
   "source": [
    "#Tensor sample size\n",
    "img_tensor, label = train_dataset[0]\n",
    "print(img_tensor.shape, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0039, 0.6039, 0.9922, 0.3529, 0.0000],\n",
      "         [0.0000, 0.5451, 0.9922, 0.7451, 0.0078],\n",
      "         [0.0000, 0.0431, 0.7451, 0.9922, 0.2745],\n",
      "         [0.0000, 0.0000, 0.1373, 0.9451, 0.8824],\n",
      "         [0.0000, 0.0000, 0.0000, 0.3176, 0.9412]]]) tensor(1.) tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "#Tensor sample values\n",
    "print(img_tensor[:, 10:15, 10:15], torch.max(img_tensor), torch.min(img_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e348de0be0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Show(plot) tensor as image\n",
    "plt.imshow(img_tensor[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set parameters\n",
    "input_size = 28 * 28\n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset loader\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    #Instantiate\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "    \n",
    "    #Pass input tensor into self.linear\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "    \n",
    "model = LogisticRegression(input_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss & Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 1/ 5], Step: [ 100/ 600], Loss: 2.2241\n",
      "Epoch: [ 1/ 5], Step: [ 200/ 600], Loss: 2.0895\n",
      "Epoch: [ 1/ 5], Step: [ 300/ 600], Loss: 2.0156\n",
      "Epoch: [ 1/ 5], Step: [ 400/ 600], Loss: 1.9285\n",
      "Epoch: [ 1/ 5], Step: [ 500/ 600], Loss: 1.9020\n",
      "Epoch: [ 1/ 5], Step: [ 600/ 600], Loss: 1.8060\n",
      "Epoch: [ 2/ 5], Step: [ 100/ 600], Loss: 1.6553\n",
      "Epoch: [ 2/ 5], Step: [ 200/ 600], Loss: 1.6352\n",
      "Epoch: [ 2/ 5], Step: [ 300/ 600], Loss: 1.6412\n",
      "Epoch: [ 2/ 5], Step: [ 400/ 600], Loss: 1.6176\n",
      "Epoch: [ 2/ 5], Step: [ 500/ 600], Loss: 1.5353\n",
      "Epoch: [ 2/ 5], Step: [ 600/ 600], Loss: 1.4439\n",
      "Epoch: [ 3/ 5], Step: [ 100/ 600], Loss: 1.4588\n",
      "Epoch: [ 3/ 5], Step: [ 200/ 600], Loss: 1.3337\n",
      "Epoch: [ 3/ 5], Step: [ 300/ 600], Loss: 1.3691\n",
      "Epoch: [ 3/ 5], Step: [ 400/ 600], Loss: 1.3639\n",
      "Epoch: [ 3/ 5], Step: [ 500/ 600], Loss: 1.1975\n",
      "Epoch: [ 3/ 5], Step: [ 600/ 600], Loss: 1.2898\n",
      "Epoch: [ 4/ 5], Step: [ 100/ 600], Loss: 1.2401\n",
      "Epoch: [ 4/ 5], Step: [ 200/ 600], Loss: 1.2479\n",
      "Epoch: [ 4/ 5], Step: [ 300/ 600], Loss: 1.1562\n",
      "Epoch: [ 4/ 5], Step: [ 400/ 600], Loss: 1.2162\n",
      "Epoch: [ 4/ 5], Step: [ 500/ 600], Loss: 1.0162\n",
      "Epoch: [ 4/ 5], Step: [ 600/ 600], Loss: 0.9586\n",
      "Epoch: [ 5/ 5], Step: [ 100/ 600], Loss: 0.9521\n",
      "Epoch: [ 5/ 5], Step: [ 200/ 600], Loss: 1.1059\n",
      "Epoch: [ 5/ 5], Step: [ 300/ 600], Loss: 0.9724\n",
      "Epoch: [ 5/ 5], Step: [ 400/ 600], Loss: 1.1126\n",
      "Epoch: [ 5/ 5], Step: [ 500/ 600], Loss: 1.0466\n",
      "Epoch: [ 5/ 5], Step: [ 600/ 600], Loss: 1.0334\n"
     ]
    }
   ],
   "source": [
    "#Model Training\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images.view(-1, 28*28)) \n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        #Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('Epoch: [% d/% d], Step: [% d/% d], Loss: %.4f'\n",
    "                  % (epoch + 1, num_epochs,\n",
    "                     i + 1, len(train_dataset) // batch_size,\n",
    "                     loss.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\aten\\src\\ATen\\native\\BinaryOps.cpp:81: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  82 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = Variable(images.view(-1, 28*28))\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy: % d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optim.SGD는 매 epoch이 끝날 때마다 업데이트 되는 weight를 자동으로 계산해준다. 따라서 optim.SGD를 사용하지 않으려면 gradient descent 알고리즘을 짜서 직접 weight를 일일히 계산해주면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기존(SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000, W: 0.311, b: -0.145 Cost: 3.333758\n",
      "Epoch  100/1000, W: 0.954, b: 0.104 Cost: 0.001555\n",
      "Epoch  200/1000, W: 0.964, b: 0.082 Cost: 0.000961\n",
      "Epoch  300/1000, W: 0.972, b: 0.064 Cost: 0.000594\n",
      "Epoch  400/1000, W: 0.978, b: 0.050 Cost: 0.000367\n",
      "Epoch  500/1000, W: 0.983, b: 0.040 Cost: 0.000227\n",
      "Epoch  600/1000, W: 0.986, b: 0.031 Cost: 0.000140\n",
      "Epoch  700/1000, W: 0.989, b: 0.025 Cost: 0.000087\n",
      "Epoch  800/1000, W: 0.992, b: 0.019 Cost: 0.000053\n",
      "Epoch  900/1000, W: 0.993, b: 0.015 Cost: 0.000033\n",
      "Epoch 1000/1000, W: 0.995, b: 0.012 Cost: 0.000020\n"
     ]
    }
   ],
   "source": [
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[1], [2], [3]])\n",
    "\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "model = LinearRegressionModel()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "num_epochs = 1000\n",
    "\n",
    "for epoch in range(num_epochs + 1):\n",
    "    prediction = model(x_train)\n",
    "    cost = torch.nn.functional.mse_loss(prediction, y_train)\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        params = list(model.parameters())\n",
    "        W = params[0].item()\n",
    "        b = params[1].item()\n",
    "        print('Epoch {:4d}/{}, W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format\n",
    "              (epoch, num_epochs, W, b, cost.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam을 사용해보았다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 W: -0.159, b: 0.218 Cost: 5.448156\n",
      "Epoch  100/1000 W: 0.522, b: 0.862 Cost: 0.164412\n",
      "Epoch  200/1000 W: 0.626, b: 0.829 Cost: 0.100215\n",
      "Epoch  300/1000 W: 0.677, b: 0.715 Cost: 0.074468\n",
      "Epoch  400/1000 W: 0.731, b: 0.596 Cost: 0.051887\n",
      "Epoch  500/1000 W: 0.782, b: 0.483 Cost: 0.034044\n",
      "Epoch  600/1000 W: 0.828, b: 0.380 Cost: 0.021076\n",
      "Epoch  700/1000 W: 0.869, b: 0.290 Cost: 0.012319\n",
      "Epoch  800/1000 W: 0.903, b: 0.216 Cost: 0.006798\n",
      "Epoch  900/1000 W: 0.930, b: 0.156 Cost: 0.003539\n",
      "Epoch 1000/1000 W: 0.951, b: 0.109 Cost: 0.001737\n"
     ]
    }
   ],
   "source": [
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[1], [2], [3]])\n",
    "\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "model = LinearRegressionModel()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "num_epochs = 1000\n",
    "\n",
    "for epoch in range(num_epochs + 1):\n",
    "    prediction = model(x_train)\n",
    "    cost = torch.nn.functional.mse_loss(prediction, y_train)\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        params = list(model.parameters())\n",
    "        W = params[0].item()\n",
    "        b = params[1].item()\n",
    "        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format\n",
    "              (epoch, num_epochs, W, b, cost.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD에 momentum을 추가해 보았다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 W: -0.484, b: -0.840 Cost: 20.204832\n",
      "Epoch  100/1000 W: 1.012, b: -0.004 Cost: 0.000380\n",
      "Epoch  200/1000 W: 1.000, b: -0.000 Cost: 0.000000\n",
      "Epoch  300/1000 W: 1.000, b: -0.000 Cost: 0.000000\n",
      "Epoch  400/1000 W: 1.000, b: -0.000 Cost: 0.000000\n",
      "Epoch  500/1000 W: 1.000, b: -0.000 Cost: 0.000000\n",
      "Epoch  600/1000 W: 1.000, b: -0.000 Cost: 0.000000\n",
      "Epoch  700/1000 W: 1.000, b: -0.000 Cost: 0.000000\n",
      "Epoch  800/1000 W: 1.000, b: -0.000 Cost: 0.000000\n",
      "Epoch  900/1000 W: 1.000, b: -0.000 Cost: 0.000000\n",
      "Epoch 1000/1000 W: 1.000, b: -0.000 Cost: 0.000000\n"
     ]
    }
   ],
   "source": [
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[1], [2], [3]])\n",
    "\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "model = LinearRegressionModel()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "num_epochs = 1000\n",
    "\n",
    "for epoch in range(num_epochs + 1):\n",
    "    prediction = model(x_train)\n",
    "    cost = torch.nn.functional.mse_loss(prediction, y_train)\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        params = list(model.parameters())\n",
    "        W = params[0].item()\n",
    "        b = params[1].item()\n",
    "        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format\n",
    "              (epoch, num_epochs, W, b, cost.item()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
