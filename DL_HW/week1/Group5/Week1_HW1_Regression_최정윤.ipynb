{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"assignment1.ipynb의 사본","provenance":[{"file_id":"1CoKbmNTW6uMU9iCQgwvx0AK_Pft9-au7","timestamp":1596099535891}],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"Z3pLNGpdh61W","colab_type":"text"},"source":["## Q1)"]},{"cell_type":"markdown","metadata":{"id":"urnwxt8wh61X","colab_type":"text"},"source":["**Type 1 error가 높다.**\n","\n","- Type 1 error는 귀무가설이 실제로 참이지만, 이에 불구하고 귀무가설을 기각하는 오류이다. 즉, 실제 음성인 것을 양성으로 판정하는 경우로 FP에 대응된다.\n","\n","\n","- 반면, Type 2 error는 귀무가설이 실제로 거짓이지만, 이에 불구하고 귀무가설을 채택하는 오류이다. 즉, 실제 양성인 것을 음성으로 판정하는 경우로 FN에 대응된다. \n","\n","따라서 threshold가 0.3으로 매우 낮아 acceptance rate이 높아지면 FP가 높고 FN이 낮아지므로, type  1 error가 높다."]},{"cell_type":"markdown","metadata":{"id":"PWJC6SPZh61X","colab_type":"text"},"source":["## Q2-1)"]},{"cell_type":"markdown","metadata":{"id":"6otzFZ7Xh61Y","colab_type":"text"},"source":["$Accuracy= {{TP+TN} \\over {TP+FN+FP+FN}}$\n","\n","$Precision= {{TP} \\over {TP+FP}}$\n","\n","$Recall= {{TP} \\over {TP+FN}}$"]},{"cell_type":"markdown","metadata":{"id":"W0lKYdJAh61Y","colab_type":"text"},"source":["## Q2-2)"]},{"cell_type":"markdown","metadata":{"id":"RykV5J_jpJDX","colab_type":"text"},"source":["**credit card fraud detection**을 예로 들 수 있다.\n","\n","고객의 카드 거래가 fraud일 확률을 예측한다고 했을 때 threshold를 낮추면 fraud detection rate가 높아진다. 이러한 경우, 고객이 조금만 자신의 원래 소비 패턴에 벗어나는 거래를 했을 경우 이를 fraud라고 예측하고 카드 거래가 정지될 수 있다. \n","\n","이 예시에서 성공확률 즉, fraud라고 탐지할 확률의 threshold를 높인다면 카드 거래 시 fraud라고 예측할 확률이 낮아진다. \n","\n","credit card의 경우 정상 거래 대비 부정 거래 비율이 매우 낮으므로, threshold를 높이는 것이 합리적이라고 할 수 있다."]},{"cell_type":"markdown","metadata":{"id":"maBEJI7Zh61c","colab_type":"text"},"source":["## Q3)"]},{"cell_type":"code","metadata":{"id":"imJ0Nz_nh61c","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596099266751,"user_tz":-540,"elapsed":1530,"user":{"displayName":"Jungyun Choi","photoUrl":"","userId":"11532088005133064485"}}},"source":["import torch\n","import torch.nn as nn\n","import torchvision.datasets as dsets\n","import torchvision.transforms as transforms\n","from torch.autograd import Variable"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"f7Oy_q5-h61f","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596099266753,"user_tz":-540,"elapsed":1523,"user":{"displayName":"Jungyun Choi","photoUrl":"","userId":"11532088005133064485"}}},"source":["# MNIST Dataset (Images and Labels)\n","train_dataset= dsets.MNIST(root='./data',\n","                           train=True,\n","                           transform=transforms.ToTensor(),\n","                           download=True)\n","test_dataset = dsets.MNIST(root ='./data',  \n","                           train = False,  \n","                           transform = transforms.ToTensor())"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"hsGykLeXj27v","colab_type":"code","colab":{}},"source":["# Hyper Parameters \n","input_size = 784\n","num_classes = 10\n","num_epochs = 5\n","batch_size = 100\n","learning_rate = 0.001\n","\n","# Dataset Loader (Input Pipline) \n","train_loader = torch.utils.data.DataLoader(dataset = train_dataset, \n","                                           batch_size = batch_size, \n","                                           shuffle = True) \n","  \n","test_loader = torch.utils.data.DataLoader(dataset = test_dataset, \n","                                          batch_size = batch_size, \n","                                          shuffle = False) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6sjbdQAnkF0v","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596099267174,"user_tz":-540,"elapsed":1914,"user":{"displayName":"Jungyun Choi","photoUrl":"","userId":"11532088005133064485"}}},"source":["# Model \n","class LogisticRegression(nn.Module): \n","    def __init__(self, input_size, num_classes): \n","        super(LogisticRegression, self).__init__() \n","        self.linear = nn.Linear(input_size, num_classes) \n","  \n","    def forward(self, x): \n","        out = self.linear(x) \n","        return out \n","  \n","  \n","model = LogisticRegression(input_size, num_classes) "],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"RL80SqPukiG0","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596099267175,"user_tz":-540,"elapsed":1906,"user":{"displayName":"Jungyun Choi","photoUrl":"","userId":"11532088005133064485"}}},"source":["# Loss and Optimizer \n","# Softmax is internally computed. \n","# Set parameters to be updated. \n","criterion = nn.CrossEntropyLoss() \n","optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate) "],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"jQo750IPkyKq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":600},"executionInfo":{"status":"ok","timestamp":1596099289776,"user_tz":-540,"elapsed":24500,"user":{"displayName":"Jungyun Choi","photoUrl":"","userId":"11532088005133064485"}},"outputId":"cae9306e-5892-412c-f04d-5f605d391319"},"source":["# Training the Model \n","for epoch in range(num_epochs): \n","    for i, (images, labels) in enumerate(train_loader): \n","        images = Variable(images.view(-1, 28 * 28)) \n","        labels = Variable(labels) \n","  \n","        # Forward + Backward + Optimize \n","        optimizer.zero_grad() \n","        outputs = model(images) \n","        loss = criterion(outputs, labels) \n","        loss.backward() \n","        optimizer.step() \n","  \n","        if (i + 1) % 100 == 0: \n","            print('Epoch: [% d/% d], Step: [% d/% d], Loss: %.4f'\n","                  % (epoch + 1, num_epochs, i + 1, \n","                     len(train_dataset) // batch_size, loss.data)) \n","  \n","# Test the Model \n","correct = 0\n","total = 0\n","for images, labels in test_loader: \n","    images = Variable(images.view(-1, 28 * 28)) \n","    outputs = model(images) \n","    _, predicted = torch.max(outputs.data, 1) \n","    total += labels.size(0) \n","    correct += (predicted == labels).sum() \n","  \n","print('Accuracy of the model on the 10000 test images: % d %%' % ( \n","            100 * correct / total)) \n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Epoch: [ 1/ 5], Step: [ 100/ 600], Loss: 2.1938\n","Epoch: [ 1/ 5], Step: [ 200/ 600], Loss: 2.0692\n","Epoch: [ 1/ 5], Step: [ 300/ 600], Loss: 2.0369\n","Epoch: [ 1/ 5], Step: [ 400/ 600], Loss: 1.9796\n","Epoch: [ 1/ 5], Step: [ 500/ 600], Loss: 1.8901\n","Epoch: [ 1/ 5], Step: [ 600/ 600], Loss: 1.8236\n","Epoch: [ 2/ 5], Step: [ 100/ 600], Loss: 1.7352\n","Epoch: [ 2/ 5], Step: [ 200/ 600], Loss: 1.5856\n","Epoch: [ 2/ 5], Step: [ 300/ 600], Loss: 1.5972\n","Epoch: [ 2/ 5], Step: [ 400/ 600], Loss: 1.5196\n","Epoch: [ 2/ 5], Step: [ 500/ 600], Loss: 1.5559\n","Epoch: [ 2/ 5], Step: [ 600/ 600], Loss: 1.4708\n","Epoch: [ 3/ 5], Step: [ 100/ 600], Loss: 1.3852\n","Epoch: [ 3/ 5], Step: [ 200/ 600], Loss: 1.3655\n","Epoch: [ 3/ 5], Step: [ 300/ 600], Loss: 1.2910\n","Epoch: [ 3/ 5], Step: [ 400/ 600], Loss: 1.2897\n","Epoch: [ 3/ 5], Step: [ 500/ 600], Loss: 1.3036\n","Epoch: [ 3/ 5], Step: [ 600/ 600], Loss: 1.2709\n","Epoch: [ 4/ 5], Step: [ 100/ 600], Loss: 1.2339\n","Epoch: [ 4/ 5], Step: [ 200/ 600], Loss: 1.1972\n","Epoch: [ 4/ 5], Step: [ 300/ 600], Loss: 1.2285\n","Epoch: [ 4/ 5], Step: [ 400/ 600], Loss: 1.2180\n","Epoch: [ 4/ 5], Step: [ 500/ 600], Loss: 1.1515\n","Epoch: [ 4/ 5], Step: [ 600/ 600], Loss: 1.0712\n","Epoch: [ 5/ 5], Step: [ 100/ 600], Loss: 1.1159\n","Epoch: [ 5/ 5], Step: [ 200/ 600], Loss: 1.0966\n","Epoch: [ 5/ 5], Step: [ 300/ 600], Loss: 1.0397\n","Epoch: [ 5/ 5], Step: [ 400/ 600], Loss: 1.0205\n","Epoch: [ 5/ 5], Step: [ 500/ 600], Loss: 0.9554\n","Epoch: [ 5/ 5], Step: [ 600/ 600], Loss: 1.0258\n","Accuracy of the model on the 10000 test images:  83 %\n"],"name":"stdout"},{"output_type":"stream","text":["/pytorch/aten/src/ATen/native/BinaryOps.cpp:81: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"_AGAG5BHnu9S","colab_type":"text"},"source":["## Q4-1)"]},{"cell_type":"code","metadata":{"id":"YQctdTREnuX8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":210},"executionInfo":{"status":"ok","timestamp":1596099290205,"user_tz":-540,"elapsed":24922,"user":{"displayName":"Jungyun Choi","photoUrl":"","userId":"11532088005133064485"}},"outputId":"3f82d3b2-15eb-4727-c465-a128b138bf6b"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","x_train = torch.FloatTensor([[1], [2], [3]])\n","y_train = torch.FloatTensor([[1], [2], [3]])\n","W = torch.zeros(1, requires_grad=True)\n","b = torch.zeros(1, requires_grad=True)\n","lr=0.01\n","\n","\n","nb_epochs = 1000\n","\n","for epoch in range(nb_epochs + 1):\n","  # H(x) 계산\n","  hypothesis = x_train * W + b\n","\n","  # cost 계산\n","  cost = torch.mean((hypothesis - y_train) ** 2)\n","  \n","  ### SGD func. 쓰지 않고 gradient 계산식 지정 \n","  W_grad = torch.sum(((W * x_train + b) - y_train) * x_train)\n","  b_grad = torch.sum((W * x_train + b) - y_train)\n","\n","  #updating W and b\n","  W.data -= lr * W_grad\n","  b.data-= lr * b_grad\n","\n","  # cost로 H(x) 개선\n","  W_grad.zero_()  # Manually zero the gradients after updating weights\n","  cost.backward()\n","    \n","  # 100번마다 로그 출력\n","  if epoch % 100 == 0:\n","      print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n","          epoch, nb_epochs, W.item(), b.item(), cost.item()\n","       ))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Epoch    0/1000 W: 0.140, b: 0.060 Cost: 4.666667\n","Epoch  100/1000 W: 0.887, b: 0.256 Cost: 0.009462\n","Epoch  200/1000 W: 0.922, b: 0.178 Cost: 0.004594\n","Epoch  300/1000 W: 0.945, b: 0.124 Cost: 0.002231\n","Epoch  400/1000 W: 0.962, b: 0.087 Cost: 0.001083\n","Epoch  500/1000 W: 0.973, b: 0.060 Cost: 0.000526\n","Epoch  600/1000 W: 0.982, b: 0.042 Cost: 0.000255\n","Epoch  700/1000 W: 0.987, b: 0.029 Cost: 0.000124\n","Epoch  800/1000 W: 0.991, b: 0.020 Cost: 0.000060\n","Epoch  900/1000 W: 0.994, b: 0.014 Cost: 0.000029\n","Epoch 1000/1000 W: 0.996, b: 0.010 Cost: 0.000014\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NykFcyIM2WOy","colab_type":"text"},"source":["## Q4-2)"]},{"cell_type":"markdown","metadata":{"id":"giPjFlvz2nJi","colab_type":"text"},"source":["### 1. Adam\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"WVzEWuWI2XLU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":210},"executionInfo":{"status":"ok","timestamp":1596099290625,"user_tz":-540,"elapsed":25335,"user":{"displayName":"Jungyun Choi","photoUrl":"","userId":"11532088005133064485"}},"outputId":"f0c30401-65a9-481b-fc89-b695516d5436"},"source":["# 데이터\n","x_train = torch.FloatTensor([[1], [2], [3]])\n","y_train = torch.FloatTensor([[1], [2], [3]])\n","\n","class LinearRegressionModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.linear = nn.Linear(1, 1)\n","\n","    def forward(self, x):\n","        return self.linear(x)\n","    \n","# 모델 초기화\n","model = LinearRegressionModel()\n","\n","# optimizer 설정\n","optimizer = optim.Adam(model.parameters(), lr=0.01)\n","\n","nb_epochs = 1000\n","for epoch in range(nb_epochs + 1):\n","    \n","    # H(x) 계산\n","    prediction = model(x_train)\n","    \n","    # cost 계산\n","    cost = F.mse_loss(prediction, y_train)\n","    \n","    # cost로 H(x) 개선\n","    optimizer.zero_grad() # 미분값이 \n","    cost.backward()\n","    optimizer.step()\n","    \n","    # 100번마다 로그 출력\n","    if epoch % 100 == 0:\n","        params = list(model.parameters())\n","        W = params[0].item()\n","        b = params[1].item()\n","        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n","            epoch, nb_epochs, W, b, cost.item()\n","        ))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Epoch    0/1000 W: 0.939, b: 0.396 Cost: 0.094274\n","Epoch  100/1000 W: 0.959, b: 0.093 Cost: 0.001307\n","Epoch  200/1000 W: 0.997, b: 0.007 Cost: 0.000007\n","Epoch  300/1000 W: 1.000, b: 0.000 Cost: 0.000000\n","Epoch  400/1000 W: 1.000, b: -0.000 Cost: 0.000000\n","Epoch  500/1000 W: 1.000, b: -0.000 Cost: 0.000000\n","Epoch  600/1000 W: 1.000, b: -0.000 Cost: 0.000000\n","Epoch  700/1000 W: 1.000, b: -0.000 Cost: 0.000000\n","Epoch  800/1000 W: 1.000, b: -0.000 Cost: 0.000000\n","Epoch  900/1000 W: 1.000, b: -0.000 Cost: 0.000000\n","Epoch 1000/1000 W: 1.000, b: -0.000 Cost: 0.000000\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"s231I8ba4-qi","colab_type":"text"},"source":["### 2. ASGD"]},{"cell_type":"code","metadata":{"id":"BVP3aFrZ2kuz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":210},"executionInfo":{"status":"ok","timestamp":1596099291094,"user_tz":-540,"elapsed":25795,"user":{"displayName":"Jungyun Choi","photoUrl":"","userId":"11532088005133064485"}},"outputId":"ddf117fa-a803-4377-b2cc-e5ecaf38640a"},"source":["# 데이터\n","x_train = torch.FloatTensor([[1], [2], [3]])\n","y_train = torch.FloatTensor([[1], [2], [3]])\n","\n","class LinearRegressionModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.linear = nn.Linear(1, 1)\n","\n","    def forward(self, x):\n","        return self.linear(x)\n","    \n","# 모델 초기화\n","model = LinearRegressionModel()\n","\n","# optimizer 설정\n","optimizer = optim.ASGD(model.parameters(), lr=0.01)\n","\n","nb_epochs = 1000\n","for epoch in range(nb_epochs + 1):\n","    \n","    # H(x) 계산\n","    prediction = model(x_train)\n","    \n","    # cost 계산\n","    cost = F.mse_loss(prediction, y_train)\n","    \n","    # cost로 H(x) 개선\n","    optimizer.zero_grad() # 미분값이 \n","    cost.backward()\n","    optimizer.step()\n","    \n","    # 100번마다 로그 출력\n","    if epoch % 100 == 0:\n","        params = list(model.parameters())\n","        W = params[0].item()\n","        b = params[1].item()\n","        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n","            epoch, nb_epochs, W, b, cost.item()\n","        ))\n"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Epoch    0/1000 W: -0.598, b: 0.241 Cost: 13.184188\n","Epoch  100/1000 W: 0.726, b: 0.622 Cost: 0.055750\n","Epoch  200/1000 W: 0.785, b: 0.489 Cost: 0.034450\n","Epoch  300/1000 W: 0.831, b: 0.384 Cost: 0.021289\n","Epoch  400/1000 W: 0.867, b: 0.302 Cost: 0.013157\n","Epoch  500/1000 W: 0.896, b: 0.238 Cost: 0.008132\n","Epoch  600/1000 W: 0.918, b: 0.187 Cost: 0.005027\n","Epoch  700/1000 W: 0.935, b: 0.147 Cost: 0.003108\n","Epoch  800/1000 W: 0.949, b: 0.115 Cost: 0.001922\n","Epoch  900/1000 W: 0.960, b: 0.091 Cost: 0.001188\n","Epoch 1000/1000 W: 0.969, b: 0.071 Cost: 0.000735\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8Cubyc3C5Hyg","colab_type":"text"},"source":["### 3. RMSprop"]},{"cell_type":"code","metadata":{"id":"PTHW12NG3GKW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":210},"executionInfo":{"status":"ok","timestamp":1596099291518,"user_tz":-540,"elapsed":26210,"user":{"displayName":"Jungyun Choi","photoUrl":"","userId":"11532088005133064485"}},"outputId":"9958207c-e42b-43ba-b613-b2c26e10b7ae"},"source":["# 데이터\n","x_train = torch.FloatTensor([[1], [2], [3]])\n","y_train = torch.FloatTensor([[1], [2], [3]])\n","\n","class LinearRegressionModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.linear = nn.Linear(1, 1)\n","\n","    def forward(self, x):\n","        return self.linear(x)\n","    \n","# 모델 초기화\n","model = LinearRegressionModel()\n","\n","# optimizer 설정\n","optimizer = optim.RMSprop(model.parameters(), lr=0.01)\n","\n","nb_epochs = 1000\n","for epoch in range(nb_epochs + 1):\n","    \n","    # H(x) 계산\n","    prediction = model(x_train)\n","    \n","    # cost 계산\n","    cost = F.mse_loss(prediction, y_train)\n","    \n","    # cost로 H(x) 개선\n","    optimizer.zero_grad() # 미분값이 \n","    cost.backward()\n","    optimizer.step()\n","    \n","    # 100번마다 로그 출력\n","    if epoch % 100 == 0:\n","        params = list(model.parameters())\n","        W = params[0].item()\n","        b = params[1].item()\n","        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n","            epoch, nb_epochs, W, b, cost.item()\n","        ))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Epoch    0/1000 W: 0.161, b: 0.351 Cost: 3.233043\n","Epoch  100/1000 W: 0.737, b: 0.581 Cost: 0.049565\n","Epoch  200/1000 W: 0.858, b: 0.315 Cost: 0.014643\n","Epoch  300/1000 W: 0.947, b: 0.117 Cost: 0.002025\n","Epoch  400/1000 W: 0.990, b: 0.023 Cost: 0.000078\n","Epoch  500/1000 W: 0.999, b: 0.002 Cost: 0.000000\n","Epoch  600/1000 W: 1.000, b: 0.000 Cost: 0.000000\n","Epoch  700/1000 W: 0.997, b: -0.003 Cost: 0.000148\n","Epoch  800/1000 W: 1.000, b: -0.000 Cost: 0.000000\n","Epoch  900/1000 W: 0.995, b: -0.005 Cost: 0.000352\n","Epoch 1000/1000 W: 0.994, b: -0.006 Cost: 0.000440\n"],"name":"stdout"}]}]}