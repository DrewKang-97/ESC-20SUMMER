{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1-1) 주석을 기반으로 코딩을 해주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate = 0.1\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MNIST dataset\n",
    "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
    "                         train = True,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
    "                        train=False,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=mnist_test,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear1 = torch.nn.Linear(784,100,bias=True)\n",
    "linear2 = torch.nn.Linear(100,100,bias=True)\n",
    "linear3 = torch.nn.Linear(100,10,bias=True)\n",
    "relu = torch.nn.ReLU()\n",
    "dropout = torch.nn.Dropout(p=0.3)\n",
    "\n",
    "bn1 = torch.nn.BatchNorm1d(100)\n",
    "bn2 = torch.nn.BatchNorm1d(100)\n",
    "\n",
    "#nn_linear1 = torch.nn.Linear(784,100,bias=True)\n",
    "#nn_linear2 = torch.nn.Linear(100,100,bias=True)\n",
    "#nn_linear3 = torch.nn.Linear(100,10,bias=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.8834e-01,  8.0911e-02, -5.7841e-02,  4.7004e-02,  5.4597e-02,\n",
       "         -2.2657e-01,  7.0984e-02,  2.0391e-01,  2.6836e-02, -4.0637e-02,\n",
       "         -2.0239e-01, -1.6156e-01,  2.0833e-01,  1.3363e-01, -3.3570e-02,\n",
       "          1.0181e-01,  2.1810e-01, -1.0430e-01, -2.3068e-01, -8.5909e-02,\n",
       "         -8.4788e-02,  1.2768e-02,  2.1248e-01,  1.1822e-01,  2.0103e-01,\n",
       "         -1.4809e-01, -8.3738e-02,  1.0027e-01,  1.5828e-01, -1.0767e-01,\n",
       "          1.9710e-01,  1.7866e-01, -2.0903e-01, -2.7886e-02, -1.8087e-01,\n",
       "         -2.6533e-03, -9.0101e-02, -2.3290e-01, -1.7138e-01, -9.2445e-02,\n",
       "          2.3105e-01,  1.0634e-01,  1.6106e-01,  9.7877e-02, -7.2314e-02,\n",
       "         -2.1307e-01, -2.0362e-02,  6.5418e-02, -1.2234e-01,  1.1297e-01,\n",
       "         -1.0994e-01,  3.3959e-02, -7.6807e-02,  1.1816e-01, -1.2633e-01,\n",
       "          2.9554e-02,  9.9724e-02, -1.2055e-01, -2.7872e-02,  2.5077e-02,\n",
       "         -8.4208e-02, -6.3669e-02, -1.5805e-02, -1.4308e-01, -1.9056e-02,\n",
       "          5.1988e-02,  1.2307e-01, -1.7463e-01,  8.0715e-03,  6.0602e-02,\n",
       "         -1.3671e-01, -2.2014e-02, -2.5540e-02,  2.1964e-01,  7.1702e-02,\n",
       "         -1.9957e-02, -1.4559e-01, -1.4695e-01, -2.0987e-01, -1.7095e-01,\n",
       "         -1.9666e-01, -6.0452e-02,  1.4991e-01, -1.2001e-01,  2.2363e-01,\n",
       "         -6.2195e-02, -4.9941e-02,  4.5144e-02, -1.7030e-01, -1.9301e-01,\n",
       "          1.5622e-01,  1.6783e-01,  1.5593e-01,  1.3838e-02,  1.2654e-01,\n",
       "         -1.9338e-01,  1.4955e-01,  2.3291e-01,  1.4166e-01, -9.6529e-02],\n",
       "        [ 8.7015e-02,  1.9798e-01,  4.4802e-02, -5.1396e-02, -1.6959e-02,\n",
       "          2.2000e-01, -8.3743e-02,  2.3069e-01,  1.8783e-01, -2.8348e-02,\n",
       "          2.2491e-01,  1.5644e-01, -1.7858e-01,  1.6035e-01,  2.2588e-01,\n",
       "          8.8704e-02,  2.2772e-01, -1.1167e-01,  1.3154e-01,  1.3617e-01,\n",
       "         -1.9021e-01, -1.1658e-01, -1.5977e-01,  5.9200e-02, -2.1062e-02,\n",
       "          7.6859e-02, -1.2712e-01,  2.0428e-01, -1.9383e-01, -8.8244e-02,\n",
       "         -4.9231e-03, -6.9049e-02, -2.1445e-02, -1.1427e-01, -5.3904e-02,\n",
       "          1.5496e-02, -1.3436e-01, -4.6107e-02, -2.0299e-01, -1.2377e-01,\n",
       "         -1.3673e-01, -1.3607e-01,  1.7272e-01,  2.0906e-01,  1.8230e-01,\n",
       "         -1.4793e-01, -8.4514e-02,  9.5478e-02, -2.1079e-01, -1.7580e-01,\n",
       "         -1.1602e-01,  8.9618e-02, -1.6508e-01, -8.1189e-02, -6.3627e-02,\n",
       "         -1.8115e-01, -1.7198e-01, -1.5836e-02, -7.5973e-02,  1.5448e-01,\n",
       "          1.9833e-01, -8.6650e-02,  1.1074e-01,  1.7345e-01,  1.9399e-01,\n",
       "          9.3306e-02, -2.5803e-02, -1.0964e-01,  2.0761e-02,  1.8429e-01,\n",
       "         -1.9337e-01,  1.1054e-02,  1.5841e-01, -1.1601e-01,  6.6574e-02,\n",
       "         -1.2321e-01, -1.4239e-01,  6.3321e-02, -1.5638e-01,  7.9194e-02,\n",
       "          6.9693e-02,  1.5000e-01, -6.3834e-02,  1.3867e-01,  5.9243e-02,\n",
       "          1.5900e-01, -2.1758e-01,  1.4615e-01,  7.3161e-02, -4.8432e-02,\n",
       "         -2.0921e-01, -5.6712e-02, -1.6306e-01,  3.5739e-02, -1.3560e-01,\n",
       "         -5.3513e-02, -2.2241e-01,  9.7663e-02, -2.1652e-01, -5.9565e-02],\n",
       "        [ 1.1689e-01,  2.1077e-01, -1.7609e-01,  2.0215e-01, -8.7199e-03,\n",
       "          2.3854e-02, -7.2580e-03, -1.2978e-01, -2.0592e-01, -1.8799e-02,\n",
       "          7.0108e-02,  1.6659e-01, -1.9995e-01,  1.5014e-02, -1.4070e-01,\n",
       "         -2.3719e-02,  1.3062e-01, -2.5181e-02,  1.4479e-01, -1.3062e-01,\n",
       "         -2.1537e-01, -1.8332e-01,  1.9424e-01,  1.3265e-01,  1.8347e-01,\n",
       "          2.9797e-03, -5.9866e-02, -1.7679e-01,  1.2136e-01,  5.6182e-02,\n",
       "          5.9797e-02, -1.9263e-01, -2.3026e-01,  4.6983e-02,  9.8219e-03,\n",
       "          1.3191e-01,  1.1953e-01, -1.5183e-01,  1.4610e-01, -5.9769e-02,\n",
       "         -1.9636e-01,  1.3380e-01,  4.3724e-02, -1.9467e-01, -4.7082e-02,\n",
       "         -1.4652e-01, -1.5142e-01,  1.5583e-01, -6.3762e-02, -2.1599e-01,\n",
       "          7.2001e-02, -1.5270e-01, -7.6331e-02, -2.3260e-01,  2.2335e-01,\n",
       "         -4.4736e-02, -3.6767e-02, -1.7263e-01,  9.9677e-02, -6.0956e-02,\n",
       "         -1.7777e-01, -6.0756e-02,  2.0016e-01,  2.0948e-01,  1.1513e-01,\n",
       "         -1.5110e-01, -6.5689e-03,  1.9667e-02, -2.1831e-01,  9.6097e-02,\n",
       "          4.6129e-02, -8.0167e-02, -2.3207e-01, -6.3427e-02,  6.8734e-03,\n",
       "         -1.7729e-01, -2.1255e-01, -1.8942e-01,  1.0895e-01,  2.2331e-01,\n",
       "         -1.5353e-01,  2.8306e-02,  2.0417e-01, -1.3320e-01,  1.4709e-01,\n",
       "         -8.9401e-02,  3.7460e-02, -1.9625e-01,  2.1902e-01, -3.0966e-02,\n",
       "         -1.6088e-01, -2.4474e-02, -6.7466e-02,  1.1902e-01, -1.0308e-01,\n",
       "         -1.1594e-01, -5.2449e-02, -1.4410e-02, -1.4941e-01, -1.4450e-01],\n",
       "        [-3.6819e-02,  6.8917e-02, -3.1796e-02,  1.6207e-02,  2.3840e-02,\n",
       "          1.4601e-01, -1.3394e-01, -1.2406e-01,  9.9085e-02,  1.9976e-01,\n",
       "         -1.1088e-01,  1.5459e-01, -1.6709e-01, -1.8708e-01,  1.7588e-01,\n",
       "         -1.4831e-01, -2.3057e-01, -3.0741e-05,  3.9236e-02,  2.1028e-01,\n",
       "          1.4729e-01,  1.8669e-01,  2.0054e-01,  2.2316e-01, -1.3356e-01,\n",
       "          1.2271e-01, -7.6329e-02,  4.7690e-02,  1.4003e-01,  3.7491e-02,\n",
       "          1.2074e-01, -4.0313e-02, -1.1301e-02, -1.3965e-01,  1.0051e-01,\n",
       "         -1.7389e-01,  1.5821e-01, -5.3500e-02, -6.0057e-02, -1.7725e-01,\n",
       "         -1.3009e-01,  4.2440e-02, -9.4541e-02,  1.0424e-01, -8.9974e-02,\n",
       "          9.2149e-02,  2.4886e-02, -5.5418e-02, -1.8239e-01,  1.7443e-01,\n",
       "          1.9692e-02,  2.2093e-02, -1.3229e-02, -6.8471e-02,  1.7115e-01,\n",
       "         -4.7265e-02, -2.2602e-01, -1.6246e-01,  1.6928e-01,  7.0608e-02,\n",
       "         -1.7780e-02, -3.2281e-02, -2.2798e-01, -1.0773e-01, -1.9372e-01,\n",
       "          1.7566e-01, -1.8659e-01, -1.7937e-01,  2.9978e-03,  1.8854e-01,\n",
       "         -9.0524e-02, -1.2604e-01, -5.1709e-02, -1.6638e-01,  1.8232e-01,\n",
       "          2.4556e-02, -1.9328e-01, -5.9666e-03, -4.4262e-02,  6.9681e-02,\n",
       "         -1.9605e-01, -1.0498e-01,  1.4962e-01,  1.9431e-03, -2.0971e-01,\n",
       "         -2.0561e-01,  1.6920e-01, -9.9105e-02, -1.5972e-01,  2.7036e-02,\n",
       "          1.2523e-01, -1.0527e-01, -1.0691e-01, -1.3006e-01, -1.3257e-01,\n",
       "         -9.7429e-02,  1.4148e-01, -1.0189e-01,  9.0470e-02,  1.7377e-01],\n",
       "        [ 9.4468e-02,  1.8348e-03, -1.9512e-01,  3.0407e-02, -9.5175e-02,\n",
       "         -2.7966e-02,  9.2005e-02,  8.0729e-02, -1.5566e-01, -5.8605e-02,\n",
       "         -1.8831e-02, -8.2670e-03,  1.0273e-01,  5.2388e-02, -7.5413e-03,\n",
       "          1.8735e-02, -1.2008e-02,  7.4750e-02,  9.9389e-02, -1.4006e-01,\n",
       "          1.6958e-01, -4.1671e-02,  1.7933e-01, -8.1063e-02, -2.6574e-02,\n",
       "          1.0372e-01,  2.2048e-01, -1.2771e-01,  1.4156e-01,  1.1846e-01,\n",
       "         -1.4364e-01, -1.3417e-01,  2.4153e-02, -2.0470e-01,  1.4737e-01,\n",
       "          2.2045e-02, -7.6538e-04, -5.6886e-02,  1.9234e-01,  6.7274e-03,\n",
       "         -6.4138e-02,  2.2589e-01, -3.8682e-03, -1.2860e-01,  6.5669e-02,\n",
       "          1.1706e-01,  8.0396e-02, -1.8062e-01, -8.2503e-02, -6.0892e-02,\n",
       "         -7.4667e-02,  2.1920e-01, -1.2589e-02, -7.6182e-02,  1.3726e-01,\n",
       "          1.1399e-01,  1.8033e-01, -2.0447e-01, -2.2515e-01,  1.1471e-01,\n",
       "         -5.0434e-02, -1.9410e-01,  1.0266e-01, -2.0083e-01,  2.0287e-01,\n",
       "         -1.8123e-01,  1.4011e-01, -1.2279e-01,  2.0089e-01,  5.4289e-02,\n",
       "          2.0577e-01, -2.0359e-01,  2.2250e-01, -2.1349e-01,  1.1147e-01,\n",
       "          2.2906e-01,  1.5921e-02, -1.8147e-01,  7.3406e-02,  2.1648e-01,\n",
       "         -1.4181e-02,  3.5324e-02,  2.1594e-01,  7.4748e-03,  1.0874e-01,\n",
       "         -1.1863e-01,  1.1224e-01, -2.1682e-01,  1.9849e-01, -1.4220e-02,\n",
       "         -1.2503e-01,  1.6301e-01,  2.2121e-01,  1.9927e-01, -2.1678e-01,\n",
       "          1.9429e-01, -9.9779e-02,  6.2961e-02,  4.3095e-02, -1.8443e-01],\n",
       "        [-9.7126e-02,  1.1189e-01, -5.8880e-03,  1.7936e-01, -5.3190e-02,\n",
       "         -2.1276e-01,  1.2056e-01, -1.5771e-01,  9.5170e-02, -1.3378e-01,\n",
       "          9.2679e-03, -3.8680e-02,  5.0729e-02, -2.0957e-01, -3.4363e-02,\n",
       "          2.3295e-01, -1.6272e-01,  2.0215e-01, -2.1968e-01, -1.3991e-01,\n",
       "          1.4037e-01, -1.1738e-01,  1.2768e-01, -1.8085e-01, -1.0441e-01,\n",
       "          7.0177e-02,  5.2127e-02, -1.6558e-01,  2.1029e-02,  1.6313e-01,\n",
       "         -4.7246e-02, -1.6513e-01, -7.3412e-02, -4.0300e-02, -3.4651e-02,\n",
       "          1.6017e-01,  2.1756e-01, -1.9491e-01,  2.1714e-01, -2.1469e-01,\n",
       "         -2.0872e-01, -1.3877e-01, -9.0953e-02,  1.1472e-01, -2.0153e-01,\n",
       "          2.1486e-01, -2.3257e-01,  1.9470e-01,  1.4317e-02, -1.9807e-01,\n",
       "         -1.8056e-02, -1.5235e-02,  1.7127e-01, -7.8523e-02, -3.9369e-02,\n",
       "          1.9329e-01, -1.7746e-02, -1.9583e-03,  6.3049e-02, -2.4982e-02,\n",
       "         -8.5938e-02, -1.6649e-01,  1.0217e-01, -7.5073e-02,  1.1980e-02,\n",
       "          1.8103e-01, -1.6360e-04,  1.6649e-01,  1.5382e-01, -4.2554e-02,\n",
       "          2.1622e-01, -7.7708e-02, -2.1224e-01, -1.2788e-02,  2.1636e-01,\n",
       "          9.6636e-02,  5.1580e-02, -2.0481e-01,  1.9580e-01,  1.5619e-01,\n",
       "         -1.1118e-01,  1.3191e-01,  7.0351e-03, -2.1733e-01, -4.0547e-03,\n",
       "         -1.2567e-01,  2.2709e-01, -6.1533e-02, -3.0186e-02,  7.3269e-02,\n",
       "         -7.5715e-02, -6.8605e-02,  1.3639e-02,  4.3827e-03, -1.3659e-01,\n",
       "         -2.1549e-01,  4.9004e-02, -4.2017e-02,  1.2566e-01,  1.9088e-01],\n",
       "        [-1.4630e-01, -7.2655e-02, -1.5727e-01, -5.5068e-02,  1.9581e-01,\n",
       "         -1.4948e-01,  1.8222e-01,  5.0851e-02, -2.2355e-01,  2.9067e-02,\n",
       "          1.5503e-01, -2.0285e-01,  7.6363e-02,  3.7819e-02,  2.1482e-01,\n",
       "         -1.3104e-01,  2.2544e-01, -1.3290e-01, -1.3806e-01,  1.1952e-01,\n",
       "         -1.3452e-01, -8.9771e-02, -1.9579e-01, -1.8025e-01, -1.7348e-01,\n",
       "          1.2299e-01,  1.3671e-01,  3.0498e-02, -1.7292e-01,  2.2739e-01,\n",
       "          9.4399e-02, -8.0755e-02,  2.5672e-02, -1.2936e-01, -1.0957e-02,\n",
       "         -1.5976e-01,  1.5357e-01, -8.4636e-03,  3.4837e-02, -2.8555e-02,\n",
       "          4.6065e-02,  1.7193e-01,  8.8131e-02, -1.2592e-01,  1.3471e-01,\n",
       "         -3.1586e-02,  1.0613e-01,  2.2387e-01, -1.7703e-01, -1.3021e-01,\n",
       "         -2.1255e-01,  1.9414e-01,  2.0488e-01,  1.6246e-01, -6.2457e-03,\n",
       "         -5.3618e-02,  2.0640e-02,  1.2068e-01, -2.0862e-01, -1.7805e-01,\n",
       "         -9.8331e-02,  2.0656e-02,  2.0599e-01, -5.1412e-02, -1.8327e-01,\n",
       "         -1.4168e-01,  6.6811e-02,  1.6665e-01,  1.4513e-01,  2.1896e-02,\n",
       "         -2.2804e-01,  2.3171e-01, -5.0461e-02, -1.6286e-01,  1.9827e-01,\n",
       "          1.6855e-01,  4.3799e-02, -1.0840e-02,  1.1782e-01,  3.4553e-02,\n",
       "         -2.7433e-02, -5.8957e-02,  2.3518e-03,  1.4653e-01,  2.1232e-01,\n",
       "         -1.7955e-02,  1.2311e-01, -6.4678e-02,  2.0224e-01, -1.0213e-02,\n",
       "         -1.8523e-01,  1.8560e-01, -2.0333e-01,  1.0659e-01, -1.8145e-02,\n",
       "          4.3245e-02,  1.6785e-01, -6.2379e-02,  1.1392e-02,  9.9537e-02],\n",
       "        [ 8.1792e-03, -4.9703e-02, -1.8672e-01, -1.5282e-01, -5.8711e-02,\n",
       "         -1.4352e-01,  9.2681e-02,  1.9113e-02, -1.6135e-02, -1.7134e-01,\n",
       "         -2.2877e-01,  1.9793e-01, -1.8667e-01,  2.0464e-01,  1.7265e-01,\n",
       "         -1.5502e-01,  1.3697e-01,  2.8867e-02,  8.9160e-02, -1.0866e-01,\n",
       "         -1.0226e-01, -1.6454e-01, -8.2301e-02,  3.7243e-02,  1.8795e-01,\n",
       "         -1.7784e-01, -5.2298e-02, -2.1462e-02, -5.6664e-02,  3.3897e-03,\n",
       "          1.3588e-01, -1.8586e-01,  1.5150e-01, -1.7580e-01,  2.3063e-01,\n",
       "          6.5507e-02,  1.3235e-01, -1.1999e-01, -9.3861e-02, -2.1639e-02,\n",
       "          1.3946e-01,  1.4847e-01,  7.3714e-02, -2.1347e-01, -7.9557e-02,\n",
       "         -3.9135e-02, -1.8564e-01, -5.8775e-02, -1.4382e-03,  3.7094e-02,\n",
       "          1.1618e-01, -1.3836e-01, -7.1223e-02,  2.1190e-01,  1.0481e-01,\n",
       "          2.4670e-02, -3.6413e-02, -1.6072e-01,  1.3976e-01, -1.9424e-01,\n",
       "          7.3885e-02,  6.6101e-02, -5.9121e-02, -8.9401e-02, -3.0127e-02,\n",
       "         -1.9145e-01,  2.3280e-01,  2.2705e-01, -1.7473e-01, -6.7909e-02,\n",
       "         -2.9976e-02,  1.3150e-01,  2.8516e-02, -4.9830e-02, -3.6391e-02,\n",
       "         -9.7953e-02,  4.6687e-02, -3.0957e-02,  7.0741e-02, -4.1310e-02,\n",
       "          2.1628e-01,  3.5235e-04, -1.7165e-01,  1.2576e-01, -1.6770e-01,\n",
       "         -6.8495e-02,  5.0230e-02,  4.1113e-02,  9.7580e-02,  6.8821e-02,\n",
       "         -3.0751e-03, -1.4474e-01, -2.2763e-01,  1.6465e-01, -2.2004e-01,\n",
       "          1.4980e-01, -1.4700e-01, -1.9157e-01,  1.6948e-01,  3.6328e-02],\n",
       "        [-1.4347e-01,  3.6477e-02, -1.1347e-01,  2.2428e-01, -5.4120e-02,\n",
       "         -1.1977e-01, -1.2128e-01,  6.8691e-02, -2.2741e-01, -2.3241e-01,\n",
       "         -1.7319e-01, -2.6596e-02, -6.6593e-02,  1.0808e-01,  1.4257e-01,\n",
       "          3.4258e-02, -1.9518e-01,  1.8703e-01, -2.0695e-01, -3.3912e-02,\n",
       "         -5.7570e-02, -2.3222e-01,  2.2133e-01, -1.7802e-01,  9.8524e-03,\n",
       "         -9.7316e-02, -1.4936e-01, -7.0416e-02,  3.1846e-02, -6.9797e-02,\n",
       "         -1.1359e-01,  2.2085e-01, -9.8451e-02, -8.9001e-02,  1.3394e-01,\n",
       "         -5.1446e-03, -4.4067e-02, -1.3967e-01,  6.4594e-02, -8.1304e-02,\n",
       "          2.1301e-03, -1.5791e-02, -1.2665e-01, -1.8513e-01, -5.2429e-02,\n",
       "          1.9694e-01,  8.7197e-02, -1.6926e-01, -1.7150e-01, -2.8342e-02,\n",
       "         -1.8772e-01,  9.6462e-02,  1.4619e-01, -2.3274e-01, -4.5699e-02,\n",
       "          2.2269e-01,  9.4260e-02,  2.9079e-02, -1.6917e-02,  2.0450e-02,\n",
       "          6.7947e-02,  1.5111e-01,  7.7482e-02, -1.3900e-01, -1.0608e-01,\n",
       "          1.6304e-01,  2.0880e-01,  9.0409e-02,  1.9391e-01,  1.0782e-01,\n",
       "         -4.6993e-02, -1.3713e-01,  9.2990e-02,  1.0790e-01, -6.2622e-02,\n",
       "         -1.2358e-01, -1.7685e-01, -1.4404e-01, -1.5078e-01,  6.1381e-02,\n",
       "         -2.9612e-02, -1.0793e-02,  4.1968e-02,  1.8939e-01, -1.5736e-01,\n",
       "         -6.6571e-02, -1.0310e-01, -1.1438e-01, -6.1769e-02,  6.0515e-02,\n",
       "          7.7337e-02,  2.1487e-01, -4.1840e-02,  1.2007e-01,  6.7713e-02,\n",
       "          1.4813e-01, -1.4743e-01,  1.0284e-01, -1.8726e-01,  9.6976e-02],\n",
       "        [-4.6151e-02, -7.2804e-02,  1.3390e-01, -1.0258e-01, -2.1402e-01,\n",
       "          1.3612e-01,  1.2495e-01, -3.5229e-02,  9.9238e-02, -1.2666e-01,\n",
       "         -1.6646e-01, -2.0783e-01, -1.6523e-01, -6.8078e-02,  1.4140e-01,\n",
       "         -2.0299e-01, -1.4141e-01, -1.3901e-01,  9.0131e-02,  1.1912e-01,\n",
       "         -4.0847e-03,  1.2596e-01,  3.1806e-02,  2.6395e-02,  2.8894e-02,\n",
       "         -1.0034e-01,  7.2244e-02, -1.1709e-02, -1.9560e-01,  1.1110e-01,\n",
       "          7.5092e-02, -9.2558e-02,  9.7778e-02, -2.2772e-01, -1.1735e-01,\n",
       "         -1.2629e-01,  2.1372e-01,  1.7504e-01,  1.0656e-01,  8.6621e-03,\n",
       "          7.0942e-02,  1.4456e-01,  7.6573e-03, -5.6450e-02, -1.9571e-01,\n",
       "         -1.0033e-02, -1.8763e-01,  2.2141e-01,  1.7146e-02,  1.6982e-01,\n",
       "         -3.0724e-02,  1.0175e-01,  1.3813e-01, -1.5828e-01, -1.2598e-01,\n",
       "         -1.4531e-02, -1.2037e-01, -1.3319e-01, -1.8186e-01,  1.6915e-02,\n",
       "         -1.0852e-01,  1.3535e-01,  1.9760e-01,  1.1500e-01,  1.4432e-01,\n",
       "         -1.0589e-01, -2.2745e-01, -1.4820e-01, -2.5206e-02,  1.9505e-01,\n",
       "         -1.2043e-01, -2.5696e-02,  2.1703e-01,  5.8285e-02,  1.9639e-01,\n",
       "          8.2179e-02,  7.6502e-02, -6.5634e-04,  1.8897e-01, -1.3395e-01,\n",
       "          1.1254e-01,  1.4088e-01, -1.1319e-01,  6.4864e-02,  2.6469e-02,\n",
       "         -7.7177e-02, -9.8706e-02,  7.4460e-02,  1.6789e-01, -8.9507e-02,\n",
       "          2.0157e-01,  2.1535e-01, -1.0645e-01,  1.4355e-01,  9.7512e-02,\n",
       "         -1.2470e-01, -2.2664e-01,  2.2803e-01, -7.0606e-02,  9.0308e-02]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## xavier initialization\n",
    "torch.nn.init.xavier_uniform_(linear1.weight)\n",
    "torch.nn.init.xavier_uniform_(linear2.weight)\n",
    "torch.nn.init.xavier_uniform_(linear3.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_model = torch.nn.Sequential(linear1,bn1,relu,dropout,\n",
    "                               linear2,bn2,relu,dropout,\n",
    "                               linear3).to(device)\n",
    "\n",
    "#nn_model = torch.nn.Sequential(nn_linear1,relu,\n",
    "#                              nn_linear2,relu,\n",
    "#                              nn_linear3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "bn_optimizer = torch.optim.Adam(bn_model.parameters(),lr=learning_rate)\n",
    "#nn_optimizer = torch.optim.Adam(nn_model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "train_total_batch = len(train_loader)\n",
    "print(train_total_batch)\n",
    "test_total_batch = len(test_loader)\n",
    "print(test_total_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 0.493593425\n",
      "Epoch: 0002 cost= 0.360244006\n",
      "Epoch: 0003 cost= 0.324935347\n",
      "Epoch: 0004 cost= 0.315062344\n",
      "Epoch: 0005 cost= 0.303531557\n",
      "Epoch: 0006 cost= 0.301063657\n",
      "Epoch: 0007 cost= 0.285570860\n",
      "Epoch: 0008 cost= 0.286456972\n",
      "Epoch: 0009 cost= 0.262443125\n",
      "Epoch: 0010 cost= 0.269874275\n",
      "Epoch: 0011 cost= 0.261900514\n",
      "Epoch: 0012 cost= 0.251416653\n",
      "Epoch: 0013 cost= 0.247882366\n",
      "Epoch: 0014 cost= 0.244977385\n",
      "Epoch: 0015 cost= 0.245383218\n",
      "Learning finished\n"
     ]
    }
   ],
   "source": [
    "# training epoch\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost= 0\n",
    "    bn_model.train()\n",
    "    \n",
    "    for x, y in train_loader:\n",
    "        x = x.view(-1,784).to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        bn_optimizer.zero_grad()\n",
    "        bn_prediction = bn_model(x)\n",
    "        bn_loss = criterion(bn_prediction,y)\n",
    "        bn_loss.backward()\n",
    "        bn_optimizer.step()\n",
    "        \n",
    "        avg_cost += bn_loss / train_total_batch \n",
    "        \n",
    "    print('Epoch:', '%04d'% (epoch+1),'cost=','{:.9f}'.format(\n",
    "        avg_cost))\n",
    "\n",
    "print('Learning finished')\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lg\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:60: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "C:\\Users\\lg\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:50: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9665998816490173\n",
      "Label:  5\n",
      "Prediction:  6\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    bn_model.eval()\n",
    "    \n",
    "    bn_acc = 0\n",
    "    \n",
    "    x_test = mnist_test.test_data.view(-1,784).float().to(device)\n",
    "    y_test = mnist_test.test_labels.to(device)\n",
    "    \n",
    "    for x, y in test_loader:\n",
    "        \n",
    "        x = x.view(-1,784).to(device)\n",
    "        y = y.to(device)\n",
    "        bn_prediction = bn_model(x)\n",
    "        bn_correct = torch.argmax(bn_prediction,dim=1)== y\n",
    "        bn_loss += criterion(bn_prediction,y)\n",
    "        bn_acc += bn_correct.float().mean()\n",
    "        \n",
    "        \n",
    "    bn_acc = bn_acc / test_total_batch\n",
    "    \n",
    "    print('Accuracy:',bn_acc.item())\n",
    "    \n",
    "    ##Test set에서 random으로 data를 뽑아 Label과 Prediction을 비교하는 코드 \n",
    "    r = random.randint(0, len(mnist_test)-1)\n",
    "    X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 *28).float()\n",
    "    Y_single_data = mnist_test.test_labels[r:r + 1]\n",
    "    \n",
    "    print('Label: ', Y_single_data.item())\n",
    "    single_prediction = bn_model(X_single_data)\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1-2) layer들의 hiddne node 수를 증가/감소 시켰을 때 train set에서의 cost와 test set에서 accuracy가 어떻게 달라졌는지 비교해주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate = 0.1\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear1 = torch.nn.Linear(784,300,bias=True)\n",
    "linear2 = torch.nn.Linear(300,200,bias=True)\n",
    "linear3 = torch.nn.Linear(200,10,bias=True)\n",
    "relu = torch.nn.ReLU()\n",
    "dropout = torch.nn.Dropout(p=0.3)\n",
    "\n",
    "bn1 = torch.nn.BatchNorm1d(300)\n",
    "bn2 = torch.nn.BatchNorm1d(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0398,  0.1154,  0.1146,  ..., -0.1328,  0.0045, -0.1422],\n",
       "        [ 0.0731,  0.0151,  0.0076,  ...,  0.1081,  0.1161,  0.1049],\n",
       "        [ 0.0097, -0.1443, -0.0501,  ...,  0.0308, -0.0815, -0.1342],\n",
       "        ...,\n",
       "        [ 0.0095, -0.1313, -0.0983,  ..., -0.1069, -0.0204, -0.0300],\n",
       "        [ 0.1610, -0.0986, -0.0824,  ..., -0.0932,  0.0568, -0.0663],\n",
       "        [ 0.1536,  0.0194,  0.1441,  ...,  0.0955, -0.0695, -0.0033]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## xavier initialization\n",
    "torch.nn.init.xavier_uniform_(linear1.weight)\n",
    "torch.nn.init.xavier_uniform_(linear2.weight)\n",
    "torch.nn.init.xavier_uniform_(linear3.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = torch.nn.Sequential(linear1,bn1,relu,dropout,\n",
    "                               linear2,bn2,relu,dropout,\n",
    "                               linear3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "bn_optimizer = torch.optim.Adam(new_model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "train_total_batch = len(train_loader)\n",
    "print(train_total_batch)\n",
    "test_total_batch = len(test_loader)\n",
    "print(test_total_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 0.446044892\n",
      "Epoch: 0002 cost= 0.318162203\n",
      "Epoch: 0003 cost= 0.278368801\n",
      "Epoch: 0004 cost= 0.249427304\n",
      "Epoch: 0005 cost= 0.249380350\n",
      "Epoch: 0006 cost= 0.232698008\n",
      "Epoch: 0007 cost= 0.224990413\n",
      "Epoch: 0008 cost= 0.212452903\n",
      "Epoch: 0009 cost= 0.207218498\n",
      "Epoch: 0010 cost= 0.192861184\n",
      "Epoch: 0011 cost= 0.190346345\n",
      "Epoch: 0012 cost= 0.183635920\n",
      "Epoch: 0013 cost= 0.190055922\n",
      "Epoch: 0014 cost= 0.184086949\n",
      "Epoch: 0015 cost= 0.177622020\n"
     ]
    }
   ],
   "source": [
    "# training epoch\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost= 0\n",
    "    new_model.train()\n",
    "    \n",
    "    for x, y in train_loader:\n",
    "        x = x.view(-1,784).to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        bn_optimizer.zero_grad()\n",
    "        bn_prediction = new_model(x)\n",
    "        bn_loss = criterion(bn_prediction,y)\n",
    "        bn_loss.backward()\n",
    "        bn_optimizer.step()\n",
    "        \n",
    "        avg_cost += bn_loss / train_total_batch \n",
    "        \n",
    "    print('Epoch:', '%04d'% (epoch+1),'cost=','{:.9f}'.format(\n",
    "        avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9699001908302307\n",
      "Label:  5\n",
      "Prediction:  5\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    new_model.eval()\n",
    "    \n",
    "    bn_acc = 0\n",
    "    \n",
    "    x_test = mnist_test.test_data.view(-1,784).float().to(device)\n",
    "    y_test = mnist_test.test_labels.to(device)\n",
    "    \n",
    "    for x, y in test_loader:\n",
    "        \n",
    "        x = x.view(-1,784).to(device)\n",
    "        y = y.to(device)\n",
    "        bn_prediction = new_model(x)\n",
    "        bn_correct = torch.argmax(bn_prediction,dim=1)== y\n",
    "        bn_loss += criterion(bn_prediction,y)\n",
    "        bn_acc += bn_correct.float().mean()\n",
    "        \n",
    "        \n",
    "    bn_acc = bn_acc / test_total_batch\n",
    "    \n",
    "    print('Accuracy:',bn_acc.item())\n",
    "    \n",
    "    ##Test set에서 random으로 data를 뽑아 Label과 Prediction을 비교하는 코드 \n",
    "    r = random.randint(0, len(mnist_test)-1)\n",
    "    X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 *28).float()\n",
    "    Y_single_data = mnist_test.test_labels[r:r + 1]\n",
    "    \n",
    "    print('Label: ', Y_single_data.item())\n",
    "    single_prediction = new_model(X_single_data)\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch: 0015 cost  감소\n",
    "Accuracy: 근소하게 증가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
