{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pylab as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# for reproducibility\n",
    "random.seed(777)\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 설정 \n",
    "learning_rate=0.1\n",
    "training_epochs=15\n",
    "batch_size=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55948f6b0f434d0f807cb62d1f7d60a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST\\raw\\train-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59196108cc164ee89541edcb740b6320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST\\raw\\train-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ded97f8341e14924ab679df9c816ba4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3304bd5811449a79b12a90a6a992ec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\torch\\csrc\\utils\\tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#MNIST data 불러오기 & train-test split\n",
    "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
    "                          train=True,\n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
    "                         train=False,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset loader에 train_test assign (*batch size, shuffle, drop_last*)\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Layering(조건: 3개의 Layer 사용, DropOut 사용 (p=0.3), relu 사용, batch normalization)\n",
    "#각 layer의 hidden node 수: (784,100), (100,100),(100,10)\n",
    "linear1 = torch.nn.Linear(784, 100, bias=True)\n",
    "linear2 = torch.nn.Linear(100, 100, bias=True)\n",
    "linear3 = torch.nn.Linear(100, 10, bias=True)\n",
    "relu=torch.nn.ReLU()\n",
    "\n",
    "bn1 = torch.nn.BatchNorm1d(100)\n",
    "bn2 = torch.nn.BatchNorm1d(100)\n",
    "dropout = torch.nn.Dropout(p=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.4783e-01, -1.3753e-01,  1.7869e-01, -1.6787e-01, -7.0605e-02,\n",
       "          2.3122e-01,  6.1109e-02, -1.6011e-01, -1.3962e-01,  8.5352e-02,\n",
       "          5.1042e-02, -1.6607e-01,  1.8580e-01,  5.3116e-02,  1.9414e-01,\n",
       "         -1.7716e-01,  2.3164e-01,  2.6270e-02, -1.4422e-01, -3.4854e-02,\n",
       "         -7.6886e-02,  1.8597e-01,  9.2216e-03, -1.8491e-01, -1.9959e-01,\n",
       "          2.5342e-03,  3.1959e-02, -1.9302e-01, -1.0948e-01, -1.8535e-01,\n",
       "          1.2680e-01, -1.3685e-02, -1.3191e-04, -1.6625e-01,  1.1506e-01,\n",
       "         -1.9070e-01,  7.0061e-02, -1.0974e-01, -1.9623e-01, -1.8040e-01,\n",
       "         -1.2158e-01, -2.2055e-01, -7.3799e-02, -2.1069e-01,  3.0007e-02,\n",
       "         -2.1656e-01,  1.5055e-01, -1.1717e-01,  1.9116e-01,  8.1463e-02,\n",
       "          9.0330e-02,  1.1348e-01,  4.2693e-02,  1.2470e-01,  3.2065e-02,\n",
       "         -1.0036e-01,  1.7607e-01,  6.9370e-02,  1.1235e-01, -7.7071e-02,\n",
       "          1.7992e-01, -6.2141e-02, -2.2293e-01,  7.0403e-02,  2.0749e-01,\n",
       "          1.5280e-01,  1.5576e-01,  6.6672e-02, -2.9035e-02, -1.9541e-01,\n",
       "          1.2402e-01,  1.5136e-01,  1.2390e-01,  8.9490e-02,  1.3104e-02,\n",
       "         -1.3618e-01,  2.0303e-01, -1.3654e-02,  1.5891e-01, -5.8839e-03,\n",
       "         -2.2743e-01, -8.8465e-02,  9.0892e-02, -8.7166e-02,  1.6700e-01,\n",
       "         -7.3514e-03, -2.4000e-02,  6.7916e-02,  2.1916e-01, -2.2390e-01,\n",
       "          1.5959e-01,  1.5689e-01, -1.0553e-01,  2.0276e-01,  1.8646e-01,\n",
       "          4.5982e-03,  5.7361e-03,  3.7072e-03,  1.5443e-01,  8.6775e-02],\n",
       "        [-3.3208e-02,  1.3045e-01, -6.0558e-02,  5.9883e-02, -1.1147e-01,\n",
       "          1.4432e-01, -1.3553e-01,  1.1308e-01, -3.5077e-02, -7.6394e-02,\n",
       "         -1.5616e-01, -1.1042e-01, -1.7277e-01, -2.2017e-02,  1.1102e-01,\n",
       "          6.9561e-02, -8.7600e-02, -1.5416e-01,  4.3044e-02, -1.3841e-02,\n",
       "         -9.7251e-02,  2.1798e-01,  5.8022e-02,  1.3823e-02, -1.4422e-01,\n",
       "         -2.3267e-03, -6.8119e-02,  1.0762e-01,  9.6858e-02,  4.6764e-02,\n",
       "          8.9116e-02, -1.4829e-01, -7.6523e-02,  4.3104e-02, -6.6162e-02,\n",
       "         -5.1990e-02,  3.0480e-02, -2.0310e-03, -1.8804e-01,  1.0011e-01,\n",
       "         -5.5176e-02, -2.5725e-02,  9.4995e-02,  1.8487e-01,  1.1594e-01,\n",
       "         -1.6527e-01,  1.4945e-01,  2.2977e-01,  2.3308e-01,  2.2118e-01,\n",
       "          3.8376e-02, -2.0818e-01, -6.2140e-02,  5.7358e-02, -3.5169e-02,\n",
       "         -1.5154e-02,  1.5388e-01, -8.6293e-02, -1.4968e-01, -8.8404e-02,\n",
       "          8.5039e-02,  1.4205e-01, -6.9667e-02,  9.7772e-02, -2.2144e-01,\n",
       "          1.9135e-01,  2.1382e-01,  1.2792e-02, -1.5005e-01,  1.9396e-01,\n",
       "          4.9058e-02, -4.7324e-02, -1.6382e-01, -1.5638e-01,  2.3037e-01,\n",
       "         -2.0431e-01,  2.1476e-02,  9.8904e-02,  2.0389e-01,  2.1665e-01,\n",
       "         -4.2684e-02, -1.9748e-01, -6.8210e-02,  8.4991e-02, -2.1798e-01,\n",
       "         -1.9828e-01, -6.6915e-02,  7.1603e-02,  3.2373e-03, -2.2904e-01,\n",
       "         -1.2862e-01,  1.2381e-01,  9.0404e-02, -2.1163e-02,  1.7635e-01,\n",
       "          1.5708e-01,  4.6804e-03, -7.3920e-02,  8.0328e-02,  4.1789e-02],\n",
       "        [-1.8815e-01, -1.2994e-01, -8.0761e-02,  1.4556e-01,  1.0872e-01,\n",
       "         -1.8962e-01,  1.6883e-01, -6.4610e-02, -5.8354e-02,  5.5607e-02,\n",
       "         -2.2215e-01,  9.2007e-03,  1.6094e-01, -1.2753e-01, -4.4442e-02,\n",
       "         -7.7160e-02, -3.0845e-02, -1.1206e-01, -2.0965e-01,  1.4031e-01,\n",
       "         -1.0908e-03, -1.6633e-01,  2.1397e-01,  1.1621e-01,  1.8881e-02,\n",
       "          1.7602e-01, -2.0005e-01,  3.0258e-02,  2.8513e-02, -1.7436e-01,\n",
       "         -1.4132e-01, -1.1908e-01, -3.9126e-03, -6.8667e-02, -1.1519e-01,\n",
       "          2.3340e-01,  8.8016e-02, -7.1049e-02,  2.1789e-01,  9.3979e-02,\n",
       "         -1.1491e-01, -3.1993e-02,  2.8803e-02,  5.8776e-02,  1.8924e-01,\n",
       "         -1.5906e-01,  1.1401e-01, -1.0312e-01,  9.5812e-02, -1.9403e-01,\n",
       "         -9.6129e-02, -1.3519e-01,  1.1163e-01, -1.3510e-01,  4.6272e-02,\n",
       "         -1.4804e-01,  2.2606e-01, -1.2023e-01, -2.1447e-01,  5.4132e-02,\n",
       "         -6.8844e-02,  1.2569e-01,  1.9162e-01, -5.4760e-02,  7.8060e-02,\n",
       "         -2.3251e-01,  2.6956e-02, -1.6439e-01, -8.8074e-02,  1.8116e-01,\n",
       "         -3.4959e-02,  3.6741e-02, -2.0316e-01,  4.4897e-02,  7.3653e-02,\n",
       "          1.9753e-02,  9.4087e-02, -2.5204e-02,  2.1434e-01, -2.1846e-01,\n",
       "          3.7286e-02, -2.1151e-01,  2.2876e-01,  1.5213e-01,  6.2217e-02,\n",
       "         -6.9145e-03,  4.7438e-02,  1.9404e-01,  1.6575e-01,  2.1043e-02,\n",
       "         -2.2976e-01, -4.8437e-02, -8.9922e-02, -1.6161e-01,  5.8532e-02,\n",
       "         -6.8353e-02, -2.2344e-01,  1.8060e-02,  2.3899e-02, -1.8674e-01],\n",
       "        [-9.9723e-02, -1.9027e-01,  3.3952e-04,  9.6499e-02,  2.1845e-01,\n",
       "         -1.5668e-01, -1.7695e-02,  9.1708e-02,  3.6717e-02,  2.1081e-01,\n",
       "          3.1728e-02, -6.6120e-02, -1.4924e-01, -2.4422e-02, -2.0549e-01,\n",
       "         -9.5581e-02,  1.8453e-01,  1.9308e-01, -5.1705e-02, -1.0112e-02,\n",
       "          2.4656e-02,  1.6793e-01, -6.0721e-02,  2.0746e-01,  5.4912e-02,\n",
       "          1.3523e-01, -5.8487e-02, -1.3356e-01,  1.0707e-01,  2.7723e-02,\n",
       "         -4.2431e-02, -6.8499e-02, -1.1855e-01,  1.1283e-01,  1.2255e-01,\n",
       "         -7.4073e-03, -7.9282e-02,  6.0667e-03, -2.3226e-01,  2.8338e-02,\n",
       "         -1.0654e-01, -2.2877e-01,  1.9544e-01, -2.2193e-01, -2.1033e-01,\n",
       "          4.7471e-02,  8.3532e-02, -2.1790e-01, -2.2004e-01, -9.2400e-02,\n",
       "          9.9244e-02,  2.1096e-01,  1.3217e-01, -1.6627e-01, -1.6720e-01,\n",
       "         -1.9228e-01,  1.1729e-01, -2.0022e-02, -5.5816e-02,  2.0601e-01,\n",
       "         -7.5834e-02,  1.2969e-01, -7.8196e-02,  1.6580e-01, -1.7557e-01,\n",
       "          1.9573e-01,  2.1571e-01, -1.8395e-01, -1.5045e-01, -1.4891e-01,\n",
       "          1.1264e-01,  2.2984e-01,  1.1075e-01, -5.3312e-02, -2.6016e-02,\n",
       "         -1.1227e-01, -2.1704e-01, -1.6808e-01,  1.6568e-01, -1.1584e-01,\n",
       "          2.0873e-01, -2.2266e-01,  1.6552e-01,  2.0174e-02,  4.5361e-02,\n",
       "         -1.7237e-01, -1.0386e-01,  2.1418e-01, -2.0484e-01, -1.0977e-01,\n",
       "          5.4847e-02, -1.9692e-01, -2.3156e-01,  9.6093e-02, -7.0212e-02,\n",
       "         -1.0458e-01, -1.7985e-02, -1.6875e-01, -2.1492e-01, -6.8192e-03],\n",
       "        [-6.5370e-02, -1.5955e-01, -1.6915e-02,  8.3710e-02,  1.1577e-01,\n",
       "         -1.9554e-01, -2.2914e-01,  2.0014e-01, -8.2706e-02,  4.3607e-02,\n",
       "          2.1948e-01, -2.2793e-01,  5.7364e-02,  2.8167e-02,  1.6874e-01,\n",
       "         -1.8913e-01,  2.4894e-02, -9.0271e-02, -4.9394e-02, -9.8392e-03,\n",
       "          2.0033e-01, -1.7008e-01,  1.5638e-01, -1.6675e-01,  1.7205e-01,\n",
       "         -1.0525e-01, -7.7206e-03, -1.0614e-01,  1.8469e-01, -9.5264e-02,\n",
       "         -1.1610e-01, -7.4753e-02, -1.4728e-01,  1.4977e-01, -8.2053e-02,\n",
       "          9.5991e-02, -8.0112e-02, -2.1603e-01,  1.3025e-01,  1.8417e-01,\n",
       "         -1.1705e-01,  1.1927e-02, -1.2189e-01, -3.8544e-02, -4.7806e-02,\n",
       "          1.2402e-01, -7.1687e-02, -1.4073e-01,  1.1678e-01, -1.4803e-01,\n",
       "         -7.9471e-02,  4.4659e-02,  1.2290e-01,  1.5093e-01, -2.3281e-01,\n",
       "          1.6629e-01,  2.0280e-01,  2.2760e-01,  7.0447e-02,  2.1031e-01,\n",
       "          1.5231e-01, -1.4206e-01, -9.6592e-02,  8.4932e-02,  1.2752e-01,\n",
       "          4.4466e-02,  1.8359e-01,  1.2240e-01,  2.3077e-01,  9.5807e-02,\n",
       "          1.9625e-01,  1.9276e-01,  5.2386e-02, -2.2834e-01, -1.7173e-01,\n",
       "          1.1848e-01, -2.2442e-01, -1.7165e-01, -1.2238e-01,  1.6741e-01,\n",
       "          1.4109e-01,  1.5791e-01, -1.8544e-01,  2.2493e-01,  1.2242e-01,\n",
       "          4.3298e-04,  1.1512e-01,  1.0221e-01, -1.5699e-01,  6.1551e-02,\n",
       "          1.5596e-01, -1.0839e-01, -2.2955e-01,  5.1462e-02,  2.3964e-03,\n",
       "         -2.3137e-01,  1.6306e-02, -1.9765e-01,  2.9588e-02, -1.3188e-02],\n",
       "        [-2.1470e-01,  2.1374e-01,  3.4081e-02,  1.2205e-01,  3.8509e-02,\n",
       "          2.2531e-01, -6.6544e-02, -2.2901e-01,  9.8052e-02, -2.1207e-01,\n",
       "          1.3137e-01,  1.1455e-01,  2.1832e-01,  3.2102e-02,  2.2461e-01,\n",
       "          2.0480e-01,  2.0688e-01, -1.0467e-01,  5.2758e-02,  1.1334e-01,\n",
       "         -6.8270e-02, -1.4370e-01,  1.4208e-01, -1.8703e-01, -1.1364e-01,\n",
       "         -1.0918e-01, -1.8891e-01,  1.8607e-01,  1.1728e-01, -2.2381e-02,\n",
       "          2.2963e-01, -1.4141e-01, -2.0176e-01, -6.0205e-02,  2.1639e-01,\n",
       "         -1.2320e-01,  2.3216e-01, -6.7242e-02,  1.4301e-01,  1.0362e-01,\n",
       "         -1.0331e-01, -2.0661e-01,  9.4527e-02, -2.2103e-01, -9.5387e-02,\n",
       "          8.0152e-02,  1.6514e-01, -1.5163e-01, -1.5490e-01,  2.1714e-01,\n",
       "         -1.0023e-02,  1.1253e-01, -5.7904e-02,  1.1628e-01, -6.5502e-02,\n",
       "         -1.5418e-01, -4.1932e-02,  2.2068e-01, -5.7652e-02, -1.9067e-01,\n",
       "          1.0853e-01,  2.2233e-01, -9.2919e-02, -1.1026e-01, -1.2860e-02,\n",
       "         -1.2601e-01, -6.7357e-02,  9.9178e-03,  1.0712e-01,  4.9920e-02,\n",
       "          2.3127e-01, -2.1547e-01, -7.8605e-02,  5.2677e-02,  1.3446e-01,\n",
       "         -2.0090e-01, -1.2861e-01,  1.6644e-01, -2.1231e-01,  2.4985e-02,\n",
       "          1.2079e-01,  9.8140e-02, -2.1402e-01,  9.5144e-02, -1.4384e-01,\n",
       "         -3.4146e-02,  2.2460e-01, -1.2810e-01, -1.4333e-02, -6.6062e-02,\n",
       "          3.3769e-02,  6.4116e-02,  2.4023e-02,  1.7688e-01,  1.7999e-01,\n",
       "         -1.6992e-01, -1.3077e-01, -3.5515e-02, -7.6753e-03, -1.1737e-01],\n",
       "        [-9.5774e-02,  1.6023e-01, -1.0288e-01,  6.1005e-02,  1.9945e-01,\n",
       "          5.6238e-02, -1.6555e-01,  2.3347e-01, -6.3258e-04,  1.3233e-02,\n",
       "          1.3183e-01,  1.4374e-01,  1.1866e-01, -5.7735e-02,  2.1295e-01,\n",
       "         -1.4451e-01,  3.5614e-02, -2.3229e-01, -1.4574e-01, -1.6568e-01,\n",
       "         -7.6190e-02, -7.4123e-02,  1.8787e-01, -1.7659e-01,  6.3617e-02,\n",
       "         -2.8659e-02, -1.6053e-01,  2.4238e-04, -2.0047e-01,  4.0913e-02,\n",
       "          1.6582e-01,  5.6275e-02,  1.3748e-01,  9.3053e-02,  2.7358e-02,\n",
       "         -1.4816e-01,  6.2086e-02,  1.0319e-01,  2.0915e-01,  6.5766e-02,\n",
       "         -1.7212e-01, -2.1564e-01,  5.8111e-02,  1.3569e-01,  1.3592e-01,\n",
       "          1.3704e-01,  1.8197e-03,  4.4333e-02, -1.2283e-01,  1.1181e-02,\n",
       "          3.2400e-02,  2.0448e-02,  1.4974e-01,  2.3496e-02,  1.4107e-01,\n",
       "         -1.0108e-01, -3.2685e-02, -9.8578e-02, -1.8289e-01,  4.5096e-02,\n",
       "          4.3545e-02,  2.0804e-01, -1.8139e-01, -2.2444e-01, -2.2233e-01,\n",
       "          2.2778e-01,  5.0118e-02, -1.8114e-01,  6.7687e-02,  1.4983e-01,\n",
       "         -2.1897e-01, -7.4232e-02,  1.9773e-01, -7.4718e-02,  7.9296e-02,\n",
       "          1.7972e-01,  5.0490e-02,  1.1921e-01, -1.0605e-01,  1.5719e-01,\n",
       "         -5.2168e-02, -2.3249e-01,  8.8994e-02, -2.3124e-03, -1.9597e-01,\n",
       "          1.0757e-01, -1.7255e-01, -3.2702e-02,  1.8909e-01, -1.6779e-02,\n",
       "         -2.2117e-01,  1.5878e-02, -2.2902e-01, -7.1788e-02,  1.9139e-01,\n",
       "          2.0061e-01,  9.3632e-02,  1.5726e-01,  1.1835e-01, -4.0809e-02],\n",
       "        [ 4.8638e-03, -4.1602e-02, -1.8704e-01, -1.3268e-01,  1.9242e-01,\n",
       "          1.8538e-01, -7.4273e-02,  6.4201e-03, -1.9045e-01, -1.3824e-01,\n",
       "         -1.7191e-01, -1.3134e-01, -1.1366e-01,  1.9968e-01,  2.2926e-02,\n",
       "          1.7609e-01, -1.0568e-01,  1.4079e-01, -5.2562e-02,  1.5881e-01,\n",
       "         -2.1991e-01,  1.0629e-01,  2.3114e-01, -1.9123e-01, -2.0181e-01,\n",
       "          6.7792e-02,  1.4884e-01, -7.2218e-02, -3.1095e-02,  1.6643e-01,\n",
       "          1.9503e-01,  1.5577e-01, -2.0460e-01, -1.1744e-01, -3.4647e-02,\n",
       "         -2.3229e-01, -8.9185e-03, -1.3394e-01, -6.7782e-02,  2.1970e-01,\n",
       "          7.8308e-02, -2.0454e-01,  1.6343e-01, -2.3145e-02, -2.2177e-01,\n",
       "         -3.2239e-02, -4.3724e-02, -9.8053e-02, -1.5976e-01,  7.8030e-02,\n",
       "          1.0480e-01, -2.0920e-01,  3.8691e-02, -1.7546e-01, -1.9942e-01,\n",
       "          1.3888e-01,  1.1786e-01,  4.9772e-02, -1.5225e-01, -8.2121e-02,\n",
       "          1.1395e-01, -8.9837e-02,  1.9489e-01, -2.0212e-02,  1.6657e-01,\n",
       "          1.7933e-01, -4.5422e-02,  1.2186e-01,  7.2663e-02, -1.0055e-03,\n",
       "          1.5588e-01, -1.3768e-01, -3.5409e-02, -6.0694e-02, -1.9828e-01,\n",
       "         -7.8880e-03,  1.5366e-01, -2.1107e-01, -1.2804e-01, -9.1080e-02,\n",
       "         -7.4312e-02,  1.0465e-01,  2.1744e-01,  1.8942e-01,  1.5387e-02,\n",
       "         -5.4683e-02,  1.4576e-01,  4.1754e-02,  1.0859e-01, -1.0710e-01,\n",
       "         -1.0345e-02,  1.5758e-01,  1.5721e-01, -2.1583e-01,  1.4469e-01,\n",
       "          2.3329e-01,  6.5020e-02, -4.8062e-02, -1.8450e-01,  8.2397e-02],\n",
       "        [ 2.2501e-01, -1.0659e-01,  3.2854e-03,  1.9733e-01,  2.2299e-02,\n",
       "          8.4263e-02, -1.4392e-01,  1.4456e-01, -1.9341e-01, -1.1059e-01,\n",
       "         -8.8209e-02, -6.1114e-02,  1.3256e-01,  7.7900e-02,  1.6245e-01,\n",
       "         -2.0987e-02, -1.5935e-01,  1.8826e-02, -1.9505e-01,  5.6656e-02,\n",
       "          1.7508e-01, -8.9577e-02,  1.3137e-01,  2.2975e-01, -3.7614e-02,\n",
       "          5.7635e-02, -1.0390e-01, -8.4398e-02, -1.0664e-01,  7.3132e-02,\n",
       "          1.3362e-01, -1.7328e-01,  1.0236e-01,  1.1050e-01, -1.2388e-01,\n",
       "         -1.9343e-01, -2.9706e-02,  2.0366e-01,  2.2435e-01,  2.2486e-01,\n",
       "         -1.8918e-01, -8.8345e-02, -1.1732e-01, -1.9299e-01, -1.8637e-01,\n",
       "          7.0550e-02, -1.5467e-01, -1.3386e-01,  1.5850e-01,  1.9068e-01,\n",
       "         -3.5814e-02, -1.7804e-01, -1.8436e-01,  6.2304e-02, -6.1623e-02,\n",
       "          2.6421e-02, -6.0133e-02,  6.4191e-02,  6.7762e-02,  1.3902e-01,\n",
       "          2.2156e-01,  1.7849e-01,  4.9275e-02, -1.6505e-01,  9.6211e-02,\n",
       "         -1.5393e-01, -1.3053e-01,  1.6139e-01, -2.6906e-03,  2.2478e-01,\n",
       "         -2.2198e-01, -6.6543e-02,  1.5413e-01,  2.2478e-01,  1.3039e-01,\n",
       "          1.7893e-01,  1.3308e-01, -6.7348e-02,  1.3783e-01,  1.4880e-01,\n",
       "         -1.2950e-01, -7.9991e-02,  1.1406e-01,  1.7929e-01, -1.0736e-01,\n",
       "          1.4328e-01, -3.6321e-02, -1.1882e-01, -2.0144e-01, -3.4552e-02,\n",
       "          1.5947e-02, -6.0067e-02,  5.2323e-02, -2.0012e-01,  1.1172e-01,\n",
       "         -4.5662e-02,  1.2629e-01,  2.3053e-01,  2.2098e-01,  7.2266e-02],\n",
       "        [-8.3433e-02, -3.3758e-02, -8.3935e-02, -1.8477e-01, -1.7212e-01,\n",
       "          8.0379e-02, -1.9456e-01,  1.4386e-01,  3.8249e-02,  9.3957e-02,\n",
       "          1.4778e-01, -1.0129e-01, -4.3901e-02, -5.9649e-02, -1.2528e-01,\n",
       "          3.7664e-02, -2.8843e-02,  1.0456e-01,  1.5225e-01,  1.5136e-01,\n",
       "         -1.4437e-01, -8.1034e-02, -1.7808e-01,  1.5122e-01,  7.4827e-03,\n",
       "          1.3008e-01,  1.9473e-01, -1.8091e-03,  3.8576e-02,  3.5926e-03,\n",
       "         -2.3264e-01,  5.3333e-02, -1.7024e-01, -1.2730e-01,  1.6596e-01,\n",
       "          2.0266e-02, -1.0049e-01,  1.7092e-01,  1.5279e-01,  1.6004e-01,\n",
       "         -1.6727e-01, -5.3723e-02, -1.5297e-01,  7.5945e-02, -5.1619e-02,\n",
       "          1.8416e-01,  2.0298e-01,  1.9950e-01, -1.5677e-01, -8.5398e-02,\n",
       "          1.9126e-01, -1.1161e-01,  2.2213e-01, -1.8346e-01, -1.4795e-02,\n",
       "         -1.9446e-01,  2.1294e-01,  1.7211e-01, -1.0498e-01,  1.4073e-01,\n",
       "         -1.2658e-01,  2.8556e-02,  1.1197e-01,  1.2843e-01, -1.2339e-01,\n",
       "         -1.7924e-01,  5.0543e-02,  2.0448e-02, -2.0335e-01, -6.8594e-02,\n",
       "          1.3936e-01,  1.4970e-01,  3.1863e-02, -4.2111e-02, -1.0140e-01,\n",
       "         -7.7511e-02, -2.2796e-01, -1.0225e-01, -4.7927e-02, -8.6683e-02,\n",
       "         -5.2407e-02, -1.8727e-01, -1.4755e-01, -1.2305e-01, -7.4655e-03,\n",
       "          1.5757e-01, -8.0924e-02, -4.7554e-02,  1.5387e-02, -1.0814e-01,\n",
       "         -1.5218e-01, -8.4948e-02, -3.5823e-02, -1.0989e-01, -1.6382e-01,\n",
       "         -1.0214e-01,  1.8850e-02,  3.5218e-02, -9.5479e-02,  6.0804e-02]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#xavier initialization \n",
    "torch.nn.init.xavier_uniform_(linear1.weight)\n",
    "torch.nn.init.xavier_uniform_(linear2.weight)\n",
    "torch.nn.init.xavier_uniform_(linear3.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.nn.Sequential을 이용하여 model 정의하기(linear->batch norm layer -> relu -> dropout)\n",
    "bn_model = torch.nn.Sequential(linear1, bn1, relu, dropout,\n",
    "                            linear2, bn2, relu, dropout,\n",
    "                            linear3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)    # Softmax is internally computed.\n",
    "optimizer = torch.optim.Adam(bn_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cost 계산을 위한 변수설정\n",
    "train_total_batch=len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.501851320\n",
      "Epoch: 0002 cost = 0.371026605\n",
      "Epoch: 0003 cost = 0.332277954\n",
      "Epoch: 0004 cost = 0.311494023\n",
      "Epoch: 0005 cost = 0.292015493\n",
      "Epoch: 0006 cost = 0.284265935\n",
      "Epoch: 0007 cost = 0.281747252\n",
      "Epoch: 0008 cost = 0.273527175\n",
      "Epoch: 0009 cost = 0.269279897\n",
      "Epoch: 0010 cost = 0.260911793\n",
      "Epoch: 0011 cost = 0.257887065\n",
      "Epoch: 0012 cost = 0.260118753\n",
      "Epoch: 0013 cost = 0.245293409\n",
      "Epoch: 0014 cost = 0.242846414\n",
      "Epoch: 0015 cost = 0.226370394\n",
      "Learning finished\n"
     ]
    }
   ],
   "source": [
    "#Training epoch (cost 값 초기설정(0으로)과 model의 train 설정 꼭 할 것)\n",
    "bn_model.train()\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    \n",
    "    #train dataset을 불러오고 (X, Y 불러오기), back propagation 과 optimizer를 사용하여 loss 최적화\n",
    "    for X, Y in data_loader:\n",
    "        # reshape input image into [batch_size by 784]\n",
    "        # label is not one-hot encoded\n",
    "        X = X.view(-1, 28 * 28).to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = bn_model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / train_total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8831999897956848\n",
      "Label:  8\n",
      "Prediction:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:60: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:50: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "#test set으로 모델의 정확도를 검증하는 코드(model의 evaluation mode 설정 꼭 할 것)\n",
    "#X_test 불러올 때 view 를 사용하여 차원 변환할 것/ Y_test를 불러올 때 labels 사용\n",
    "#accuracy의 초기값 설정(0으로) 꼭 할 것\n",
    "# Test model and check accuracy\n",
    "with torch.no_grad():\n",
    "    bn_model.eval()    # set the model to evaluation mode (dropout=False)\n",
    "\n",
    "    # Test the model using test sets\n",
    "    X_test = mnist_test.test_data.view(-1, 28 * 28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "\n",
    "    prediction = bn_model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())\n",
    "\n",
    "    #test set에서 random으로 data를 뽑아, label과 prediction을 비교하는 코드\n",
    "    # Get one and predict\n",
    "    r = random.randint(0, len(mnist_test) - 1)\n",
    "    X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 * 28).float().to(device)\n",
    "    Y_single_data = mnist_test.test_labels[r:r + 1].to(device)\n",
    "\n",
    "    print('Label: ', Y_single_data.item())\n",
    "    single_prediction = bn_model(X_single_data)\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Layering(조건: 3개의 Layer 사용, DropOut 사용 (p=0.3), relu 사용, batch normalization)\n",
    "#각 layer의 hidden node 수: (784,200), (200,150),(150,10)\n",
    "linear1 = torch.nn.Linear(784, 200, bias=True)\n",
    "linear2 = torch.nn.Linear(200, 150, bias=True)\n",
    "linear3 = torch.nn.Linear(150, 10, bias=True)\n",
    "relu=torch.nn.ReLU()\n",
    "\n",
    "bn1 = torch.nn.BatchNorm1d(200)\n",
    "bn2 = torch.nn.BatchNorm1d(150)\n",
    "dropout = torch.nn.Dropout(p=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0117, -0.0844, -0.1313,  ..., -0.0317, -0.1657, -0.1573],\n",
       "        [ 0.0203,  0.1654,  0.1569,  ...,  0.0952,  0.0191, -0.0985],\n",
       "        [-0.1679, -0.1461, -0.0127,  ...,  0.0205,  0.1855, -0.0867],\n",
       "        ...,\n",
       "        [-0.1440, -0.1677,  0.1842,  ..., -0.1669,  0.1412, -0.1020],\n",
       "        [-0.0626,  0.1092, -0.1658,  ..., -0.0144,  0.1504, -0.0100],\n",
       "        [ 0.0201, -0.0080, -0.0462,  ..., -0.1851,  0.1637, -0.0795]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#xavier initialization \n",
    "torch.nn.init.xavier_uniform_(linear1.weight)\n",
    "torch.nn.init.xavier_uniform_(linear2.weight)\n",
    "torch.nn.init.xavier_uniform_(linear3.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.nn.Sequential을 이용하여 model 정의하기(linear->batch norm layer -> relu -> dropout)\n",
    "bn_model = torch.nn.Sequential(linear1, bn1, relu, dropout,\n",
    "                            linear2, bn2, relu, dropout,\n",
    "                            linear3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)    # Softmax is internally computed.\n",
    "optimizer = torch.optim.Adam(bn_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cost 계산을 위한 변수설정\n",
    "train_total_batch=len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.463630527\n",
      "Epoch: 0002 cost = 0.326863289\n",
      "Epoch: 0003 cost = 0.290368140\n",
      "Epoch: 0004 cost = 0.275735795\n",
      "Epoch: 0005 cost = 0.268540889\n",
      "Epoch: 0006 cost = 0.250680059\n",
      "Epoch: 0007 cost = 0.234645382\n",
      "Epoch: 0008 cost = 0.232912704\n",
      "Epoch: 0009 cost = 0.224910527\n",
      "Epoch: 0010 cost = 0.220604822\n",
      "Epoch: 0011 cost = 0.216830239\n"
     ]
    }
   ],
   "source": [
    "#Training epoch (cost 값 초기설정(0으로)과 model의 train 설정 꼭 할 것)\n",
    "bn_model.train()\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    \n",
    "    #train dataset을 불러오고 (X, Y 불러오기), back propagation 과 optimizer를 사용하여 loss 최적화\n",
    "    for X, Y in data_loader:\n",
    "        # reshape input image into [batch_size by 784]\n",
    "        # label is not one-hot encoded\n",
    "        X = X.view(-1, 28 * 28).to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = bn_model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / train_total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test set으로 모델의 정확도를 검증하는 코드(model의 evaluation mode 설정 꼭 할 것)\n",
    "#X_test 불러올 때 view 를 사용하여 차원 변환할 것/ Y_test를 불러올 때 labels 사용\n",
    "#accuracy의 초기값 설정(0으로) 꼭 할 것\n",
    "# Test model and check accuracy\n",
    "with torch.no_grad():\n",
    "    bn_model.eval()    # set the model to evaluation mode (dropout=False)\n",
    "\n",
    "    # Test the model using test sets\n",
    "    X_test = mnist_test.test_data.view(-1, 28 * 28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "\n",
    "    prediction = bn_model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())\n",
    "\n",
    "    #test set에서 random으로 data를 뽑아, label과 prediction을 비교하는 코드\n",
    "    # Get one and predict\n",
    "    r = random.randint(0, len(mnist_test) - 1)\n",
    "    X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 * 28).float().to(device)\n",
    "    Y_single_data = mnist_test.test_labels[r:r + 1].to(device)\n",
    "\n",
    "    print('Label: ', Y_single_data.item())\n",
    "    single_prediction = bn_model(X_single_data)\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
