{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pylab as plt\n",
    "import random\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 설정 (learning rate, training epochs, batch_size)\n",
    "learning_rate = 0.1\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train과 test set으로 나누어 MNIST data 불러오기\n",
    "train_dataset = dsets.MNIST(root='MNIST_data', train=True,\n",
    "                      transform=transforms.ToTensor())\n",
    "test_dataset = dsets.MNIST(root='MNIST_data', train=False,\n",
    "                      transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset loader에 train과 test할당하기(batch size, shuffle, drop_last 잘 설정할 것!)\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size,\n",
    "                          shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size,\n",
    "                         shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer 쌓기 (조건: 3개의 Layer 사용, DropOut 사용 (p=0.3), ReLU 함수 사용, Batch normalization하기)\n",
    "# 각 Layer의 Hidden node 수 : 1st Layer (784,100), 2nd Layer(100,100),3rd Layer(100,10)\n",
    "linear1 = torch.nn.Linear(784, 100, bias=True)\n",
    "linear2 = torch.nn.Linear(100, 100, bias=True)\n",
    "linear3 = torch.nn.Linear(100, 10, bias=True)\n",
    "\n",
    "dropout = torch.nn.Dropout(p=0.3)\n",
    "relu = torch.nn.ReLU()\n",
    "\n",
    "bn1 = torch.nn.BatchNorm1d(100)\n",
    "bn2 = torch.nn.BatchNorm1d(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-1.8456e-01, -1.0288e-01, -1.8460e-01,  9.8734e-02,  1.9576e-01,\n",
       "         -1.1690e-01, -7.3035e-02,  1.7796e-01,  8.3608e-02,  2.9346e-02,\n",
       "          7.5124e-04,  3.6764e-02,  4.8139e-02,  1.7494e-01,  3.5080e-02,\n",
       "         -7.1267e-02,  9.2584e-02,  1.4563e-01, -2.2576e-01, -9.6950e-02,\n",
       "          7.8035e-02, -1.4205e-01,  1.0978e-01,  1.3822e-01,  9.8931e-02,\n",
       "          9.0927e-02, -1.2801e-01, -9.7189e-02, -1.6117e-01, -1.7466e-02,\n",
       "         -8.4207e-02, -1.8178e-01,  2.2356e-01, -7.3179e-02,  1.4821e-01,\n",
       "         -5.1725e-02,  2.1346e-02,  7.7231e-02,  6.5650e-03, -1.5362e-01,\n",
       "         -2.2148e-01, -1.3293e-01,  1.8341e-01, -5.8854e-02,  1.6075e-01,\n",
       "         -1.0289e-01,  2.1212e-01, -8.3755e-02,  2.1887e-01, -1.8897e-01,\n",
       "         -2.1393e-01,  4.3875e-02, -4.2989e-02,  1.9082e-01,  1.8661e-02,\n",
       "         -2.1566e-01, -1.3035e-01, -9.5964e-02,  1.0613e-01, -8.4691e-02,\n",
       "         -2.0427e-01, -1.8781e-01, -2.0166e-01, -4.8597e-02, -1.4990e-01,\n",
       "         -1.0347e-01, -3.8586e-02,  4.4256e-02,  1.7053e-01,  1.8521e-01,\n",
       "          2.0785e-01,  1.3281e-01,  1.7533e-01,  2.2825e-01, -1.1424e-02,\n",
       "         -4.9072e-02,  1.9300e-01,  1.0652e-01,  9.5983e-02,  1.8265e-02,\n",
       "         -1.8339e-01,  8.4805e-02,  7.7790e-02,  2.0933e-01, -1.8468e-01,\n",
       "          9.7821e-02,  9.5333e-02,  1.6659e-02,  8.2280e-02, -6.4239e-02,\n",
       "         -7.4173e-02, -8.8809e-03, -5.0936e-02,  2.0339e-01, -1.3087e-01,\n",
       "         -7.0488e-02, -8.6771e-02, -1.3024e-01, -2.1764e-01, -1.7745e-01],\n",
       "        [-2.2677e-01,  1.6500e-01,  7.1563e-02,  2.2639e-01, -1.1374e-01,\n",
       "          1.5224e-01,  7.3468e-02,  1.8349e-01,  1.3820e-01, -1.9398e-01,\n",
       "         -2.0624e-01,  1.8445e-01, -6.0663e-02, -5.3639e-02,  1.3840e-01,\n",
       "          2.2407e-01, -8.9120e-02, -1.6005e-02, -9.7240e-02,  1.1654e-03,\n",
       "          2.0572e-01,  5.6374e-02,  1.7571e-01, -5.8415e-02, -1.8280e-01,\n",
       "         -2.0641e-01,  1.5950e-01,  5.6067e-02, -1.3660e-01, -1.3001e-01,\n",
       "          1.8207e-01, -2.2754e-01, -1.9692e-01,  2.1703e-01, -3.7602e-03,\n",
       "         -3.4934e-02, -8.7143e-02, -1.6093e-01, -6.0541e-02, -5.8123e-02,\n",
       "         -7.9800e-02, -1.8293e-01,  1.7801e-01,  4.4655e-02,  8.3356e-02,\n",
       "         -8.3290e-02, -1.6100e-01, -1.0827e-01, -1.7198e-01, -1.4458e-01,\n",
       "          1.2178e-01, -7.9039e-02,  7.0346e-02, -1.4228e-02,  6.5902e-03,\n",
       "         -1.8392e-01,  8.1752e-02, -1.5367e-01, -2.2198e-01,  1.9791e-01,\n",
       "          1.4810e-01, -2.1174e-01, -1.0013e-01,  1.5945e-01, -5.6832e-02,\n",
       "          2.1099e-01,  4.3237e-02, -1.6432e-01,  2.4944e-02, -4.1633e-02,\n",
       "         -1.3931e-01, -2.0890e-01, -1.1470e-01, -9.5782e-03, -1.1533e-01,\n",
       "         -2.9542e-02,  9.3053e-02, -2.0210e-01,  1.7369e-02, -1.5475e-01,\n",
       "          1.2302e-01, -4.4710e-02,  1.5742e-01,  5.7873e-02,  3.6586e-02,\n",
       "         -1.4958e-03,  8.8722e-02,  1.2236e-01, -2.3268e-01, -2.5239e-02,\n",
       "          1.3212e-01,  8.6393e-02,  9.9620e-02,  1.9326e-01,  1.7235e-01,\n",
       "         -1.0601e-01, -7.2380e-02, -1.5908e-01, -7.0799e-02,  2.7356e-02],\n",
       "        [ 7.8117e-02,  1.0530e-01,  3.4746e-02,  7.0237e-02, -6.2445e-02,\n",
       "         -2.0199e-01,  1.8965e-01, -7.3382e-02, -7.7178e-02,  5.1311e-02,\n",
       "          2.1363e-01, -5.7361e-02, -2.2315e-01, -8.4245e-02,  1.2074e-01,\n",
       "         -6.5636e-02, -1.7798e-01, -8.8774e-02,  1.4609e-01, -5.0016e-02,\n",
       "          6.6559e-02,  4.0512e-02,  7.8514e-02,  1.7111e-02, -1.3077e-01,\n",
       "         -8.6860e-02, -2.3032e-01, -8.9878e-02,  1.4604e-01,  1.5794e-01,\n",
       "         -4.1972e-02, -1.2868e-01, -1.7020e-02,  1.0514e-01, -2.0785e-01,\n",
       "          1.8079e-01, -3.8973e-02,  9.2777e-02, -1.3555e-01,  1.3960e-01,\n",
       "          1.2961e-01, -4.7024e-02,  2.2801e-01, -8.8573e-02,  1.9609e-01,\n",
       "          1.9504e-01,  4.9374e-02,  4.7481e-02,  3.0064e-03,  8.0429e-02,\n",
       "          2.0606e-01,  2.0394e-01,  1.2926e-01,  3.7426e-02,  1.9078e-01,\n",
       "          2.3039e-01,  2.1984e-01,  1.7366e-01,  2.0592e-01, -1.6760e-01,\n",
       "          2.1819e-01,  2.0248e-01, -2.2361e-01, -9.0592e-02,  1.2306e-01,\n",
       "         -1.2636e-01, -1.5874e-01,  1.4622e-01, -4.2486e-02, -6.1473e-03,\n",
       "         -1.9737e-01,  1.7982e-01,  8.0961e-02,  2.4495e-03,  1.4174e-01,\n",
       "          1.1820e-01, -1.7327e-01,  1.9157e-01,  9.0690e-02, -5.6533e-02,\n",
       "         -8.0950e-02, -1.2638e-01,  1.1406e-01, -2.2684e-01,  1.3878e-01,\n",
       "          1.4445e-01, -8.9528e-02,  1.2919e-01,  1.4251e-01, -2.1294e-01,\n",
       "         -2.3061e-01,  7.8540e-02,  1.4070e-01, -2.0213e-01, -9.6984e-02,\n",
       "         -1.1315e-01, -9.3083e-02,  4.1703e-02, -1.2817e-01, -1.8128e-01],\n",
       "        [-1.3802e-01, -7.6718e-02, -1.8796e-01,  1.0679e-01,  1.4776e-01,\n",
       "         -7.0800e-02, -4.1318e-02,  1.7898e-01, -8.2057e-02, -1.4076e-01,\n",
       "         -1.1653e-01, -1.3587e-01, -9.8034e-02,  2.1742e-01,  1.4661e-01,\n",
       "          1.3209e-01, -1.7515e-01, -1.7288e-01, -1.7716e-01,  2.0324e-01,\n",
       "         -8.8746e-02,  1.9478e-01,  2.2460e-01, -1.3484e-01, -2.1217e-01,\n",
       "         -1.9412e-01, -2.2702e-01,  1.5253e-01, -5.9828e-02, -1.2531e-01,\n",
       "          3.6333e-03,  1.7679e-01, -7.6058e-02,  1.1800e-01, -1.2126e-02,\n",
       "         -3.2606e-02, -5.9216e-02,  9.6767e-02, -1.5166e-01, -1.1295e-01,\n",
       "         -2.2040e-01, -3.5012e-03, -1.1901e-01,  1.6487e-01, -3.7255e-02,\n",
       "         -1.6327e-01, -2.0781e-01, -1.8359e-01,  1.9382e-01,  1.1573e-01,\n",
       "         -1.1023e-01,  1.7406e-02, -1.0016e-01, -4.7826e-02, -7.8603e-02,\n",
       "          1.4119e-01,  1.2090e-01, -3.1758e-02,  1.6170e-01, -1.7301e-01,\n",
       "          9.7336e-02, -2.3007e-01,  1.0844e-01,  9.8991e-02, -1.5263e-01,\n",
       "         -1.4760e-01, -2.5756e-02,  1.6784e-01,  9.6964e-02,  2.2695e-01,\n",
       "         -1.4863e-01, -2.0553e-01, -1.0834e-01,  8.0943e-02, -1.5645e-01,\n",
       "         -2.6622e-02, -1.2123e-01, -2.7797e-02, -8.6329e-02, -1.3166e-01,\n",
       "          1.1969e-01,  1.6181e-01, -3.7422e-02, -2.0581e-01,  4.7285e-02,\n",
       "          1.7257e-01,  1.1672e-01, -7.4573e-02,  2.2557e-01, -1.1995e-01,\n",
       "          1.6043e-01,  2.0442e-01,  1.3389e-01,  1.9352e-01,  1.8087e-01,\n",
       "          7.2624e-02,  1.4775e-01,  1.3574e-02,  4.5002e-03,  1.0949e-02],\n",
       "        [ 4.8946e-02, -1.3088e-01, -5.5030e-02,  9.0612e-02, -2.1827e-01,\n",
       "          6.0419e-02,  4.8444e-02, -6.4476e-02,  2.1218e-01, -1.2897e-01,\n",
       "          3.1213e-03,  2.5985e-02, -2.2592e-01, -1.8586e-01,  1.9284e-01,\n",
       "         -9.7215e-02, -1.6904e-01, -5.9197e-02,  2.1407e-01, -1.5004e-01,\n",
       "          1.9437e-01, -7.1532e-02, -8.6155e-02,  2.2320e-01, -9.3125e-02,\n",
       "          2.8996e-02, -1.4393e-02, -9.8573e-02,  2.2894e-01,  1.7671e-02,\n",
       "          2.2252e-01,  2.2531e-01, -2.9369e-02, -2.1600e-02,  1.1053e-01,\n",
       "         -6.6141e-02, -3.4608e-02, -3.8906e-02, -6.2775e-02, -1.9835e-01,\n",
       "         -5.7374e-02, -3.9882e-02, -4.9642e-02,  1.3052e-02, -1.2057e-01,\n",
       "         -1.4488e-01, -2.9609e-02,  1.4282e-01, -1.9263e-01,  8.2369e-02,\n",
       "         -2.2576e-02, -1.3420e-01,  1.4631e-01,  2.0556e-01,  3.1563e-02,\n",
       "         -1.0368e-01, -2.3288e-01,  1.0554e-01,  2.0763e-01, -1.8621e-01,\n",
       "          1.2765e-01,  2.0164e-01, -1.2148e-01, -1.7215e-01, -4.4242e-02,\n",
       "         -1.9845e-01, -2.9682e-02, -1.9090e-01,  2.1236e-01,  2.2869e-01,\n",
       "          2.1834e-01, -2.0162e-01,  8.8641e-02,  1.1559e-01, -1.3534e-01,\n",
       "         -1.5651e-01,  1.5072e-01, -1.1569e-01,  1.6504e-01, -1.0961e-02,\n",
       "          1.6695e-01,  2.1871e-01,  7.9010e-02,  2.1495e-01, -9.4447e-02,\n",
       "         -2.0859e-01,  3.6888e-03,  1.1482e-01, -1.4056e-01, -1.1396e-01,\n",
       "         -1.6787e-01, -4.7603e-02, -1.6118e-01,  1.2309e-01, -3.0865e-02,\n",
       "          2.1481e-01,  1.5205e-01,  1.0342e-01,  1.6658e-01,  1.6705e-01],\n",
       "        [ 9.0336e-02,  4.9825e-02,  6.4144e-02, -6.4104e-02,  1.2406e-01,\n",
       "         -4.9975e-02,  2.0231e-01,  1.5985e-01,  1.0365e-01,  1.9739e-01,\n",
       "          8.7718e-02, -1.3304e-01,  1.3260e-01,  8.6498e-02, -1.4336e-01,\n",
       "          6.3434e-02,  2.2100e-01,  1.1890e-03, -1.5580e-01, -6.8792e-02,\n",
       "          1.0446e-01,  1.7652e-01, -1.0790e-01, -1.5973e-02,  5.9989e-02,\n",
       "          8.0129e-02, -5.8319e-02,  1.7869e-01,  7.6956e-02,  6.7454e-03,\n",
       "         -1.1328e-02,  1.7929e-02,  1.4034e-01,  1.7236e-01,  2.2153e-01,\n",
       "         -3.7173e-03, -2.0846e-01,  1.3103e-01,  9.8435e-02,  1.2044e-01,\n",
       "         -1.5437e-01, -4.1009e-02, -1.7258e-01, -6.3355e-02,  7.3522e-05,\n",
       "          1.3308e-01,  1.7970e-01, -7.2649e-02, -1.4935e-01, -8.9797e-02,\n",
       "          3.6161e-02, -6.0384e-03,  2.0747e-01,  1.1043e-01, -1.4489e-02,\n",
       "          5.5288e-03,  1.8077e-01,  5.7111e-02,  1.7951e-02, -1.5303e-01,\n",
       "          1.0707e-01, -1.4166e-01, -4.1614e-02,  1.8802e-01,  1.2912e-01,\n",
       "          2.2405e-01, -1.3847e-01, -1.1621e-01, -1.4015e-02,  1.5326e-01,\n",
       "          7.7487e-02,  1.7649e-01, -1.8610e-01, -6.2508e-02,  2.0966e-01,\n",
       "         -1.4400e-01,  7.8812e-02, -5.5759e-02,  6.3217e-02, -7.9970e-02,\n",
       "          1.9266e-01, -2.3022e-01,  1.4316e-01, -4.9505e-02,  1.2921e-01,\n",
       "          2.1872e-01,  1.8568e-01,  1.6011e-01, -2.1066e-01, -2.0643e-01,\n",
       "          2.9345e-02, -2.2824e-01,  1.5851e-01, -9.8541e-03, -6.4884e-02,\n",
       "          2.1219e-01,  1.1442e-01,  9.5623e-03, -1.3460e-01,  5.8789e-02],\n",
       "        [ 1.9305e-01, -1.2053e-01,  4.9156e-02, -1.5808e-01,  1.2061e-01,\n",
       "         -4.9838e-02,  8.6126e-02, -2.2442e-01, -2.4172e-02, -6.5715e-02,\n",
       "          9.3056e-02, -7.4349e-02, -9.9194e-02,  7.4456e-02, -1.8642e-01,\n",
       "         -8.4812e-02, -4.7136e-02, -2.3073e-01, -1.0327e-01, -3.1178e-02,\n",
       "          1.5930e-02,  1.6477e-01, -5.9819e-02, -2.0542e-01, -1.6842e-01,\n",
       "         -2.1166e-01, -6.0374e-02, -1.8990e-01,  2.6174e-02,  9.5265e-02,\n",
       "         -2.1591e-01, -7.7112e-02, -1.1481e-01, -2.1093e-01, -2.1367e-02,\n",
       "          1.0054e-01,  8.9928e-02,  1.2441e-02,  1.5862e-01, -1.6342e-01,\n",
       "         -1.4626e-01,  8.3159e-02,  1.4758e-01, -1.5248e-02,  6.7825e-02,\n",
       "          9.6891e-02,  1.4959e-02,  9.1727e-02, -5.8947e-02, -2.1337e-01,\n",
       "         -2.2561e-02,  2.2779e-01, -1.1611e-01,  9.5839e-02, -7.8250e-02,\n",
       "          4.8730e-02, -1.7716e-01, -1.3482e-01, -1.2210e-01, -3.3348e-02,\n",
       "          2.0656e-01,  1.6257e-01,  7.6173e-03,  5.1292e-02,  2.0105e-01,\n",
       "         -6.3779e-02, -2.0763e-01,  1.6188e-01,  2.0713e-01, -3.5192e-02,\n",
       "         -1.4456e-01, -1.6369e-01,  1.3718e-01,  1.8344e-01, -2.0761e-01,\n",
       "         -7.3138e-02,  9.0866e-02,  9.7519e-02, -3.7237e-02,  2.0166e-01,\n",
       "         -1.5921e-01, -1.8797e-01,  1.3538e-01, -1.8853e-01,  2.1697e-01,\n",
       "          1.2178e-02,  1.3495e-01, -6.5469e-02, -1.5570e-01, -4.1744e-02,\n",
       "          8.1119e-03, -2.2639e-01, -1.6124e-01,  7.4940e-02,  8.4947e-04,\n",
       "          1.9397e-01, -1.9202e-01,  2.0564e-01, -1.0335e-01,  1.1580e-01],\n",
       "        [-8.1819e-02,  1.5745e-01, -1.7407e-01, -4.4953e-02,  9.8237e-02,\n",
       "          1.6804e-01, -1.7276e-01, -1.3938e-01, -1.3436e-01,  9.7388e-02,\n",
       "         -1.7119e-01, -5.4085e-02, -1.7505e-02, -2.0165e-01,  1.4514e-01,\n",
       "          1.0778e-01, -3.8680e-02,  1.7082e-01, -1.6532e-01,  2.6857e-02,\n",
       "         -5.7615e-02,  2.0132e-01, -1.0556e-01, -1.1240e-01,  1.6203e-01,\n",
       "         -1.2727e-02, -1.3741e-01, -2.0310e-01, -6.4614e-03,  1.9331e-01,\n",
       "          4.8689e-02, -1.5400e-01,  6.6976e-02, -1.8149e-01, -8.0566e-02,\n",
       "         -8.7234e-02, -5.8308e-02,  2.1523e-01, -2.2495e-01,  1.3376e-01,\n",
       "          6.3674e-03,  1.4348e-01,  1.2613e-01,  4.4096e-02,  3.9062e-02,\n",
       "         -1.2148e-01,  3.9870e-02, -1.5151e-01, -7.0943e-02,  4.1913e-02,\n",
       "          1.6573e-01,  1.2666e-01,  1.0488e-01,  1.0846e-01, -3.3723e-02,\n",
       "         -1.0005e-01, -1.0751e-01, -8.5569e-02, -2.0618e-01,  1.6487e-01,\n",
       "         -5.5765e-02,  1.9197e-01,  1.6368e-01,  6.7572e-02, -1.9204e-02,\n",
       "          1.3141e-02, -1.9815e-01,  2.0166e-01, -7.3000e-02,  1.4902e-01,\n",
       "          5.1756e-02,  4.6985e-02,  2.0102e-01,  1.1908e-01, -1.1290e-01,\n",
       "         -2.1516e-01, -2.6308e-02,  4.7730e-02,  3.8972e-02, -8.0216e-02,\n",
       "          1.7433e-01,  2.7789e-02,  2.1226e-01,  1.6513e-01, -1.7666e-01,\n",
       "         -3.0184e-02,  2.2998e-01,  2.1517e-01,  1.8616e-01,  1.1871e-01,\n",
       "         -1.4548e-01, -9.4662e-02, -1.7327e-01, -8.2653e-02, -2.5750e-02,\n",
       "         -4.2176e-02,  2.3058e-01, -1.5263e-02, -1.9083e-01,  1.7988e-01],\n",
       "        [ 5.0641e-02, -1.8344e-01,  2.0947e-01,  5.7299e-02,  1.6304e-01,\n",
       "          1.6802e-01, -1.3924e-01,  4.5383e-02,  1.8342e-01,  2.0205e-01,\n",
       "          1.6785e-01,  1.5588e-01,  2.5423e-02,  7.6865e-02,  1.3550e-01,\n",
       "          1.0754e-02, -1.1955e-01, -1.1002e-01,  1.4932e-01,  4.3311e-02,\n",
       "          8.8179e-02,  2.0074e-01,  1.8102e-01,  1.5405e-03,  2.0577e-01,\n",
       "          3.9102e-02,  7.4509e-02, -2.0584e-01,  1.7394e-01,  1.9945e-01,\n",
       "          1.7206e-01,  1.1946e-01,  9.6361e-02, -1.9000e-01, -2.1111e-01,\n",
       "          1.8653e-01, -2.0096e-01,  1.4288e-01, -1.8862e-01,  1.7429e-01,\n",
       "         -1.7182e-01,  1.6849e-01,  7.9098e-02, -1.4486e-01,  3.9854e-02,\n",
       "         -2.2051e-01, -2.1682e-01,  2.1881e-01, -2.1667e-01,  6.5834e-02,\n",
       "          1.2789e-01,  2.3185e-02, -3.3981e-02, -2.2138e-01, -1.6737e-01,\n",
       "         -3.9138e-02,  2.3089e-01,  1.0083e-01,  1.4811e-01,  3.3091e-02,\n",
       "         -1.8678e-01, -1.5113e-01, -7.4376e-02, -1.9406e-01,  1.8139e-01,\n",
       "         -2.1187e-02,  8.3379e-02, -1.4865e-01,  2.1516e-01, -2.1039e-01,\n",
       "          1.9370e-01,  7.8535e-02, -8.1185e-02, -3.3010e-02,  7.4651e-02,\n",
       "          2.3173e-01,  7.9848e-02,  3.3877e-02, -7.1390e-02, -7.9392e-02,\n",
       "         -1.4572e-01, -9.2874e-02, -4.7266e-03, -1.0382e-01, -9.0314e-03,\n",
       "         -1.3493e-01,  2.0762e-01, -7.0086e-02,  2.7084e-02,  1.2178e-01,\n",
       "          1.2640e-01, -2.1311e-01, -1.3435e-01, -7.0841e-02, -5.6255e-02,\n",
       "         -1.9231e-01, -1.7407e-01,  7.6149e-02, -1.7239e-01, -2.1286e-01],\n",
       "        [-1.0742e-01,  8.3279e-02,  1.6505e-01,  5.6582e-02, -2.0022e-01,\n",
       "         -6.0317e-03, -6.7895e-02,  2.0670e-01, -1.7207e-01,  5.4829e-02,\n",
       "          1.1427e-01,  5.0876e-02,  4.7057e-02, -7.7268e-02, -1.6647e-01,\n",
       "         -1.9926e-01, -2.1555e-01,  9.6438e-02, -4.2750e-02, -7.7928e-02,\n",
       "          1.6675e-01,  1.9281e-01, -3.0576e-03,  2.0395e-01, -1.2794e-01,\n",
       "         -1.2229e-01, -3.5565e-02,  1.4977e-01,  2.2445e-01,  2.1213e-01,\n",
       "         -4.0033e-02,  1.1904e-01, -5.4339e-02,  1.4307e-01,  8.1028e-02,\n",
       "         -1.6105e-01,  6.1446e-02,  4.8386e-02, -2.7021e-02,  1.9866e-01,\n",
       "          1.7146e-01, -3.4107e-02, -2.1788e-01, -3.4340e-02, -1.9449e-01,\n",
       "         -7.5295e-02, -5.0246e-02, -1.6645e-01, -2.1998e-01, -1.9369e-01,\n",
       "         -8.0530e-02,  3.1551e-02, -1.7055e-01,  1.4096e-01, -7.6408e-03,\n",
       "          6.8315e-02, -2.1115e-01, -5.5583e-02,  2.3482e-02, -7.6787e-02,\n",
       "         -4.2647e-02, -4.3237e-02, -2.0292e-01,  2.3247e-01,  6.7469e-02,\n",
       "         -1.7687e-01,  7.5638e-02, -6.2875e-03,  1.2954e-01, -9.6677e-02,\n",
       "         -9.8585e-02,  1.5810e-01,  1.0225e-01,  1.3362e-01,  6.8107e-02,\n",
       "          6.9414e-02, -9.4032e-02,  8.5150e-02, -1.7891e-01, -2.0862e-01,\n",
       "          2.0083e-01,  1.0595e-01,  3.0773e-02, -3.6534e-02,  1.2112e-01,\n",
       "         -6.7238e-02, -1.0498e-01, -1.4990e-01,  1.6313e-01,  1.7083e-01,\n",
       "          2.3316e-01,  4.1992e-02, -1.1875e-01, -5.8295e-02, -2.0200e-01,\n",
       "          2.3129e-01, -2.0753e-01, -2.4381e-02, -2.1428e-01, -9.9945e-02]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#xavier initialization을 이용하여 각 layer의 weight 초기화\n",
    "torch.nn.init.xavier_uniform_(linear1.weight)\n",
    "torch.nn.init.xavier_uniform_(linear2.weight)\n",
    "torch.nn.init.xavier_uniform_(linear3.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.nn.Sequential을 이용하여 model 정의하기(쌓는 순서: linear-Batch Normalization Layer - ReLU- DropOut)\n",
    "model = torch.nn.Sequential(linear1, bn1, relu, dropout, linear2, bn2, relu, dropout, linear3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function 정의하기 (CrossEntropy를 사용할 것!)\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer 정의하기 (Adam optimizer를 사용할 것!)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cost 계산을 위한 변수 설정\n",
    "train_total_batch = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.503435910\n",
      "Epoch: 0002 cost = 0.365048051\n",
      "Epoch: 0003 cost = 0.334249139\n",
      "Epoch: 0004 cost = 0.302047849\n",
      "Epoch: 0005 cost = 0.303128302\n",
      "Epoch: 0006 cost = 0.281297147\n",
      "Epoch: 0007 cost = 0.275884509\n",
      "Epoch: 0008 cost = 0.269686431\n",
      "Epoch: 0009 cost = 0.259295195\n",
      "Epoch: 0010 cost = 0.261926115\n",
      "Epoch: 0011 cost = 0.255251110\n",
      "Epoch: 0012 cost = 0.248109043\n",
      "Epoch: 0013 cost = 0.254848748\n",
      "Epoch: 0014 cost = 0.242148101\n",
      "Epoch: 0015 cost = 0.235981181\n",
      "Learning finished\n"
     ]
    }
   ],
   "source": [
    "#Training epoch (cost 값 초기 설정(0으로)과 model의 train 설정 꼭 할 것) \n",
    "model.train()\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    \n",
    "#train dataset을 불러오고(X,Y 불러오기), back propagation과 optimizer를 사용하여 loss를 최적화하는 코드    \n",
    "    for X, Y in train_loader:\n",
    "        # reshape input image into [batch_size by 784]\n",
    "        # label is not one-hot encoded\n",
    "        X = X.view(-1, 28 * 28).to(device)\n",
    "        Y = Y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_cost += cost / train_total_batch\n",
    "        \n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "    \n",
    "print('Learning finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sec\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:60: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "C:\\Users\\sec\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:50: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9366000294685364\n",
      "Label:  6\n",
      "Prediction:  6\n"
     ]
    }
   ],
   "source": [
    "#test data로 모델의 정확도를 검증하는 코드 (model의 evaluation mode 설정 꼭 할 것)\n",
    "#X_test 불러올 때 view를 사용하여 차원 변환할 것/ Y_test를 불러올때 labels사용\n",
    "#accuracy의 초기 값 설정(0으로) 꼭 할 것\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    X_test = test_dataset.test_data.view(-1, 28 * 28).float().to(device)\n",
    "    Y_test = test_dataset.test_labels.to(device)\n",
    "    \n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())\n",
    "\n",
    "    ##Test set에서 random으로 data를 뽑아 Label과 Prediction을 비교하는 코드\n",
    "    r = random.randint(0, len(test_dataset) - 1)\n",
    "    X_single_data = test_dataset.test_data[r:r + 1].view(-1, 28 * 28).float().to(device)\n",
    "    Y_single_data = test_dataset.test_labels[r:r + 1].to(device)\n",
    "\n",
    "    print('Label: ', Y_single_data.item())\n",
    "    single_prediction = model(X_single_data)\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear1 = torch.nn.Linear(784, 200, bias=True)\n",
    "linear2 = torch.nn.Linear(200, 150, bias=True)\n",
    "linear3 = torch.nn.Linear(150, 10, bias=True)\n",
    "\n",
    "relu = torch.nn.ReLU()\n",
    "dropout = torch.nn.Dropout(p=0.3)\n",
    "\n",
    "bn1 = torch.nn.BatchNorm1d(200)\n",
    "bn2 = torch.nn.BatchNorm1d(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1609, -0.1106, -0.0153,  ..., -0.0826, -0.1499,  0.1354],\n",
       "        [-0.1761,  0.1137,  0.0819,  ...,  0.0894, -0.1467, -0.0995],\n",
       "        [-0.0313,  0.0049, -0.1319,  ...,  0.0149, -0.1753,  0.1601],\n",
       "        ...,\n",
       "        [-0.1923, -0.0557,  0.0464,  ...,  0.0191, -0.0793,  0.1561],\n",
       "        [-0.0153, -0.1482, -0.0116,  ..., -0.1368, -0.1072,  0.1538],\n",
       "        [-0.1457, -0.0847,  0.0137,  ..., -0.1606, -0.0393,  0.1047]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.init.xavier_uniform_(linear1.weight)\n",
    "torch.nn.init.xavier_uniform_(linear2.weight)\n",
    "torch.nn.init.xavier_uniform_(linear3.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(linear1, bn1, relu, dropout, linear2, bn2, relu, dropout, linear3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_total_batch = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.472110003\n",
      "Epoch: 0002 cost = 0.332314372\n",
      "Epoch: 0003 cost = 0.288377047\n",
      "Epoch: 0004 cost = 0.267691672\n",
      "Epoch: 0005 cost = 0.257264644\n",
      "Epoch: 0006 cost = 0.238321006\n",
      "Epoch: 0007 cost = 0.232339770\n",
      "Epoch: 0008 cost = 0.229101345\n",
      "Epoch: 0009 cost = 0.226597697\n",
      "Epoch: 0010 cost = 0.211771518\n",
      "Epoch: 0011 cost = 0.209984258\n",
      "Epoch: 0012 cost = 0.204505101\n",
      "Epoch: 0013 cost = 0.208193734\n",
      "Epoch: 0014 cost = 0.184867427\n",
      "Epoch: 0015 cost = 0.196432039\n",
      "Learning finished\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    \n",
    "#train dataset을 불러오고(X,Y 불러오기), back propagation과 optimizer를 사용하여 loss를 최적화하는 코드    \n",
    "    for X, Y in train_loader:\n",
    "        # reshape input image into [batch_size by 784]\n",
    "        # label is not one-hot encoded\n",
    "        X = X.view(-1, 28 * 28).to(device)\n",
    "        Y = Y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_cost += cost / train_total_batch\n",
    "        \n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "    \n",
    "print('Learning finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sec\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:60: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "C:\\Users\\sec\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:50: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9157000184059143\n",
      "Label:  6\n",
      "Prediction:  6\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    X_test = test_dataset.test_data.view(-1, 28 * 28).float().to(device)\n",
    "    Y_test = test_dataset.test_labels.to(device)\n",
    "    \n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())\n",
    "\n",
    "    ##Test set에서 random으로 data를 뽑아 Label과 Prediction을 비교하는 코드\n",
    "    r = random.randint(0, len(test_dataset) - 1)\n",
    "    X_single_data = test_dataset.test_data[r:r + 1].view(-1, 28 * 28).float().to(device)\n",
    "    Y_single_data = test_dataset.test_labels[r:r + 1].to(device)\n",
    "\n",
    "    print('Label: ', Y_single_data.item())\n",
    "    single_prediction = model(X_single_data)\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "큰 차이는 없어 보인다"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
